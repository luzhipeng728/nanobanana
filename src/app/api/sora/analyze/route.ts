import { NextRequest } from "next/server";
import Anthropic from "@anthropic-ai/sdk";
import { CLAUDE_LIGHT_MODEL, CLAUDE_LIGHT_MAX_TOKENS } from "@/lib/claude-config";

export interface SoraAnalyzeEvent {
  type: "status" | "analysis_start" | "analysis_chunk" | "analysis_end" | "prompt_ready" | "error";
  step?: string;
  progress?: number;
  chunk?: string;
  prompt?: string;
  analysis?: string;
  error?: string;
}

/**
 * Sora2 è§†é¢‘æç¤ºè¯ä¼˜åŒ– API
 * ç®€æ´å®ç”¨ï¼Œä¸“æ³¨äºç”Ÿæˆæœ‰æ•ˆçš„è§†é¢‘åŠ¨ä½œæè¿°
 */
export async function POST(request: NextRequest) {
  const encoder = new TextEncoder();

  const stream = new TransformStream();
  const writer = stream.writable.getWriter();

  const sendEvent = async (event: SoraAnalyzeEvent) => {
    await writer.write(encoder.encode(`data: ${JSON.stringify(event)}\n\n`));
  };

  (async () => {
    try {
      const body = await request.json();
      const { userRequest, imageUrl, durationSeconds = 8 } = body as {
        userRequest: string;
        imageUrl?: string;
        durationSeconds?: number;
      };

      if (!userRequest) {
        await sendEvent({ type: "error", error: "è¯·è¾“å…¥è§†é¢‘æè¿°" });
        await writer.close();
        return;
      }

      const apiKey = process.env.ANTHROPIC_API_KEY;
      if (!apiKey) {
        await sendEvent({ type: "error", error: "ANTHROPIC_API_KEY æœªé…ç½®" });
        await writer.close();
        return;
      }

      const anthropic = new Anthropic({
        apiKey,
        baseURL: process.env.ANTHROPIC_BASE_URL || undefined,
      });

      let imageAnalysis = "";

      // æœ‰å›¾ç‰‡æ—¶ï¼šåˆ†æå›¾ç‰‡å†…å®¹
      if (imageUrl) {
        await sendEvent({
          type: "status",
          step: "ğŸ‘ï¸ åˆ†æå›¾ç‰‡å†…å®¹...",
          progress: 10,
        });

        await sendEvent({ type: "analysis_start" });

        // æ„å»ºå›¾ç‰‡å†…å®¹
        const imageContent: Anthropic.ImageBlockParam[] = [];
        if (imageUrl.startsWith("data:")) {
          const match = imageUrl.match(/^data:([^;]+);base64,(.+)$/);
          if (match) {
            imageContent.push({
              type: "image",
              source: {
                type: "base64",
                media_type: match[1] as "image/jpeg" | "image/png" | "image/gif" | "image/webp",
                data: match[2],
              },
            });
          }
        } else {
          imageContent.push({
            type: "image",
            source: {
              type: "url",
              url: imageUrl,
            },
          });
        }

        // ç®€æ´çš„å›¾ç‰‡åˆ†æ
        const analysisStream = anthropic.messages.stream({
          model: CLAUDE_LIGHT_MODEL,
          max_tokens: 1024,
          messages: [
            {
              role: "user",
              content: [
                ...imageContent,
                {
                  type: "text",
                  text: `åˆ†æè¿™å¼ å›¾ç‰‡ï¼Œä¸ºç”Ÿæˆ ${durationSeconds} ç§’è§†é¢‘åšå‡†å¤‡ã€‚

ç”¨æˆ·æƒ³è¦çš„åŠ¨ä½œï¼š${userRequest}

è¯·ç®€æ´æè¿°ï¼š
1. **ç”»é¢ä¸»ä½“**ï¼šäººç‰©å¤–è§‚ã€æœè£…ã€è¡¨æƒ…ã€å§¿æ€
2. **åœºæ™¯ç¯å¢ƒ**ï¼šåœ°ç‚¹ã€å…‰çº¿ã€æ°›å›´
3. **åŠ¨ä½œå»ºè®®**ï¼šåŸºäºç”¨æˆ·æƒ³æ³•ï¼Œè®¾è®¡è‡ªç„¶æµç•…çš„åŠ¨ä½œ

ç”¨ä¸­æ–‡ç®€æ´å›ç­”ã€‚`,
                },
              ],
            },
          ],
        });

        for await (const event of analysisStream) {
          if (event.type === "content_block_delta" && event.delta.type === "text_delta") {
            const chunk = event.delta.text;
            imageAnalysis += chunk;
            await sendEvent({ type: "analysis_chunk", chunk });
          }
        }

        await sendEvent({ type: "analysis_end" });
      } else {
        // æ— å›¾ç‰‡ï¼šç›´æ¥ä¼˜åŒ–æç¤ºè¯
        await sendEvent({
          type: "status",
          step: "ğŸ¬ æ„æ€è§†é¢‘ç”»é¢...",
          progress: 10,
        });

        await sendEvent({ type: "analysis_start" });

        const thinkingStream = anthropic.messages.stream({
          model: CLAUDE_LIGHT_MODEL,
          max_tokens: 1024,
          messages: [
            {
              role: "user",
              content: `åŸºäºç”¨æˆ·æè¿°ï¼Œæ„æ€ä¸€ä¸ª ${durationSeconds} ç§’çš„è§†é¢‘ç”»é¢ã€‚

ç”¨æˆ·æè¿°ï¼š${userRequest}

è¯·ç®€æ´è®¾è®¡ï¼š
1. **ç”»é¢ä¸»ä½“**ï¼šäººç‰©/ç‰©ä½“çš„å¤–è§‚ç»†èŠ‚
2. **åœºæ™¯ç¯å¢ƒ**ï¼šåœ°ç‚¹ã€æ—¶é—´ã€å…‰çº¿ã€æ°›å›´
3. **åŠ¨ä½œè®¾è®¡**ï¼š${durationSeconds}ç§’å†…çš„åŠ¨ä½œæµç¨‹

ç”¨ä¸­æ–‡ç®€æ´å›ç­”ã€‚`,
            },
          ],
        });

        for await (const event of thinkingStream) {
          if (event.type === "content_block_delta" && event.delta.type === "text_delta") {
            const chunk = event.delta.text;
            imageAnalysis += chunk;
            await sendEvent({ type: "analysis_chunk", chunk });
          }
        }

        await sendEvent({ type: "analysis_end" });
      }

      await sendEvent({
        type: "status",
        step: "âœ¨ ç”Ÿæˆè§†é¢‘æç¤ºè¯...",
        progress: 60,
      });

      // ç”Ÿæˆæœ€ç»ˆæç¤ºè¯ - ç®€æ´æœ‰æ•ˆ
      const promptResponse = await anthropic.messages.create({
        model: CLAUDE_LIGHT_MODEL,
        max_tokens: 512,
        messages: [
          {
            role: "user",
            content: `åŸºäºä»¥ä¸‹åˆ†æï¼Œç”Ÿæˆä¸€æ®µè§†é¢‘ç”Ÿæˆæç¤ºè¯ã€‚

## åˆ†æå†…å®¹ï¼š
${imageAnalysis}

## ç”¨æˆ·åŸå§‹æè¿°ï¼š
${userRequest}

## è§†é¢‘æ—¶é•¿ï¼š${durationSeconds} ç§’

## è¦æ±‚ï¼š
1. æç¤ºè¯è¦å…·ä½“æè¿°åŠ¨ä½œè¿‡ç¨‹ï¼Œä¸è¦åªæè¿°é™æ€ç”»é¢
2. åŒ…å«è¡¨æƒ…ã€çœ¼ç¥ã€è‚¢ä½“åŠ¨ä½œç­‰ç»†èŠ‚
3. æè¿°ç¯å¢ƒæ°›å›´ã€å…‰çº¿å˜åŒ–
4. ä¿æŒè‡ªç„¶æµç•…ï¼Œé€‚åˆ ${durationSeconds} ç§’æ—¶é•¿
5. ç”¨è‹±æ–‡è¾“å‡ºï¼ˆè§†é¢‘æ¨¡å‹å¯¹è‹±æ–‡æ•ˆæœæ›´å¥½ï¼‰
6. ç›´æ¥è¾“å‡ºæç¤ºè¯ï¼Œä¸è¦ä»»ä½•è§£é‡Š

ç¤ºä¾‹æ ¼å¼ï¼š
"A young woman with long black hair stands in a sunlit garden. She slowly turns her head toward the camera, her eyes meeting the lens with a gentle smile forming on her lips. The golden hour light catches her hair as a soft breeze lifts a few strands. Her expression shifts from contemplative to warmly inviting as she tilts her head slightly."`,
          },
        ],
      });

      const textBlock = promptResponse.content.find(
        (block): block is Anthropic.TextBlock => block.type === "text"
      );

      let generatedPrompt = textBlock?.text?.trim() || userRequest;

      // æ¸…ç†å¯èƒ½çš„å¼•å·åŒ…è£¹
      if (generatedPrompt.startsWith('"') && generatedPrompt.endsWith('"')) {
        generatedPrompt = generatedPrompt.slice(1, -1);
      }

      await sendEvent({
        type: "status",
        step: "âœ… æç¤ºè¯å·²å°±ç»ªï¼",
        progress: 100,
      });

      await sendEvent({
        type: "prompt_ready",
        prompt: generatedPrompt,
        analysis: imageAnalysis || undefined,
      });
    } catch (error) {
      console.error("Sora analyze error:", error);
      await sendEvent({
        type: "error",
        error: error instanceof Error ? error.message : "åˆ†æå¤±è´¥",
      });
    } finally {
      await writer.close();
    }
  })();

  return new Response(stream.readable, {
    headers: {
      "Content-Type": "text/event-stream",
      "Cache-Control": "no-cache",
      Connection: "keep-alive",
    },
  });
}
