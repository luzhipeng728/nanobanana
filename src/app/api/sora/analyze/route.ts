import { NextRequest } from "next/server";
import Anthropic from "@anthropic-ai/sdk";
import { CLAUDE_LIGHT_MODEL, CLAUDE_LIGHT_MAX_TOKENS } from "@/lib/claude-config";

export interface SoraAnalyzeEvent {
  type: "status" | "analysis_start" | "analysis_chunk" | "analysis_end" | "prompt_ready" | "error";
  step?: string;
  progress?: number;
  chunk?: string;
  prompt?: string;
  analysis?: string;
  error?: string;
}

/**
 * Sora 2 è§†é¢‘æ™ºèƒ½åˆ†æ API
 * åŸºäº OpenAI Cookbook å®˜æ–¹ Sora 2 Prompting Guide æœ€ä½³å®è·µ
 *
 * æ ¸å¿ƒç»“æ„ï¼šStyle â†’ Scene â†’ Cinematography â†’ Actions â†’ Background Sound
 * åƒç»™æ‘„å½±å›¢é˜Ÿåš briefing ä¸€æ ·å†™æç¤ºè¯
 */
export async function POST(request: NextRequest) {
  const encoder = new TextEncoder();

  const stream = new TransformStream();
  const writer = stream.writable.getWriter();

  const sendEvent = async (event: SoraAnalyzeEvent) => {
    await writer.write(encoder.encode(`data: ${JSON.stringify(event)}\n\n`));
  };

  (async () => {
    try {
      const body = await request.json();
      const { userRequest, imageUrl, durationSeconds = 8 } = body as {
        userRequest: string;
        imageUrl?: string;
        durationSeconds?: number;
      };

      if (!userRequest) {
        await sendEvent({ type: "error", error: "è¯·è¾“å…¥è§†é¢‘æè¿°" });
        await writer.close();
        return;
      }

      const apiKey = process.env.ANTHROPIC_API_KEY;
      if (!apiKey) {
        await sendEvent({ type: "error", error: "ANTHROPIC_API_KEY æœªé…ç½®" });
        await writer.close();
        return;
      }

      const anthropic = new Anthropic({
        apiKey,
        baseURL: process.env.ANTHROPIC_BASE_URL || undefined,
      });

      let imageAnalysis = "";

      // ç¬¬ä¸€é˜¶æ®µï¼šè¯¦ç»†åˆ†æå›¾ç‰‡
      if (imageUrl) {
        await sendEvent({
          type: "status",
          step: "ğŸ‘ï¸ AI æ­£åœ¨åˆ†æå›¾ç‰‡å†…å®¹...",
          progress: 10,
        });

        await sendEvent({ type: "analysis_start" });

        // æ„å»ºå›¾ç‰‡å†…å®¹
        const imageContent: Anthropic.ImageBlockParam[] = [];
        if (imageUrl.startsWith("data:")) {
          const match = imageUrl.match(/^data:([^;]+);base64,(.+)$/);
          if (match) {
            imageContent.push({
              type: "image",
              source: {
                type: "base64",
                media_type: match[1] as "image/jpeg" | "image/png" | "image/gif" | "image/webp",
                data: match[2],
              },
            });
          }
        } else {
          imageContent.push({
            type: "image",
            source: {
              type: "url",
              url: imageUrl,
            },
          });
        }

        // æµå¼åˆ†æå›¾ç‰‡ - åŸºäº Sora 2 Cookbook å®˜æ–¹æœ€ä½³å®è·µ
        const analysisStream = anthropic.messages.stream({
          model: CLAUDE_LIGHT_MODEL,
          max_tokens: CLAUDE_LIGHT_MAX_TOKENS,
          messages: [
            {
              role: "user",
              content: [
                ...imageContent,
                {
                  type: "text",
                  text: `ä½ æ˜¯ä¸€ä½ä¸“ä¸šç”µå½±æ‘„å½±å¸ˆï¼Œæ­£åœ¨ä¸º Sora 2 è§†é¢‘ç”Ÿæˆåˆ†æè¿™å¼ å›¾ç‰‡ã€‚
åƒç»™æ‘„å½±å›¢é˜Ÿåš briefing ä¸€æ ·ï¼Œè¯¦ç»†æè¿°å¦‚ä½•å°†è¿™å¼ é™æ€å›¾ç‰‡å˜æˆ ${durationSeconds} ç§’çš„ç”µå½±çº§è§†é¢‘ã€‚

ç”¨æˆ·çš„åˆ›æ„æƒ³æ³•ï¼š${userRequest}

è¯·æŒ‰ä»¥ä¸‹ Sora 2 å®˜æ–¹æ¨èç»“æ„åˆ†æï¼š

## 1. Style é£æ ¼å®šä½
- ç”µå½±é£æ ¼/å¹´ä»£æ„Ÿï¼ˆå¦‚ï¼šç°ä»£ç”µå½±ã€å¤å¤èƒ¶ç‰‡ã€çºªå½•ç‰‡é£æ ¼ç­‰ï¼‰
- è§†è§‰ç¾å­¦ï¼ˆè‰²è°ƒå€¾å‘ã€è´¨æ„Ÿã€æ°›å›´ï¼‰
- å‚è€ƒé£æ ¼ï¼ˆå¦‚æœ‰ï¼‰

## 2. Scene åœºæ™¯æè¿°
- **ç¯å¢ƒ**ï¼šå…·ä½“åœ°ç‚¹ã€æ—¶é—´ï¼ˆç™½å¤©/å¤œæ™š/é»„é‡‘æ—¶æ®µï¼‰
- **ä¸»ä½“**ï¼šäººç‰©/ç‰©ä½“çš„è¯¦ç»†å¤–è§‚ï¼ˆæœè£…ã€å‘å‹ã€è¡¨æƒ…ã€å§¿æ€ï¼‰
- **ç©ºé—´å±‚æ¬¡**ï¼šå‰æ™¯ã€ä¸­æ™¯ã€èƒŒæ™¯å„æœ‰ä»€ä¹ˆå…ƒç´ 
- **æ°›å›´ç»†èŠ‚**ï¼šå¤©æ°”ã€æ¸©åº¦æ„Ÿã€ç¯å¢ƒç²’å­ï¼ˆç°å°˜/é›¨æ»´/èŠ±ç“£ç­‰ï¼‰

## 3. Cinematography æ‘„å½±è®¾è®¡
- **Camera æœºä½**ï¼šæ™¯åˆ«ï¼ˆwide/medium/close-upï¼‰ã€è§’åº¦ï¼ˆå¹³è§†/ä¿¯æ‹/ä»°æ‹ï¼‰
- **Lens é•œå¤´**ï¼šç„¦è·å»ºè®®ï¼ˆ24mmå¹¿è§’/35mm/50mmæ ‡å‡†/85mmäººåƒï¼‰
- **Movement è¿åŠ¨**ï¼šé™æ­¢/æ¨è¿›(dolly-in)/è·Ÿè¸ª/æ¨ªæ‘‡(pan)/æ‘‡ç§»
- **Depth æ™¯æ·±**ï¼šæµ…æ™¯æ·±ï¼ˆçªå‡ºä¸»ä½“ï¼‰æˆ–æ·±æ™¯æ·±ï¼ˆå±•ç¤ºç¯å¢ƒï¼‰
- **Lighting å…‰çº¿**ï¼šä¸»å…‰æ–¹å‘ã€è‰²æ¸©ã€è´¨æ„Ÿï¼ˆç¡¬å…‰/æŸ”å…‰ï¼‰

## 4. Actions åŠ¨ä½œè®¾è®¡ (${durationSeconds}ç§’æ—¶é—´çº¿)
æ ¹æ® ${durationSeconds} ç§’æ—¶é•¿è®¾è®¡è¿è´¯çš„åŠ¨ä½œåºåˆ—ï¼š
${durationSeconds <= 4
  ? "- èšç„¦å•ä¸€å…³é”®åŠ¨ä½œæˆ–æƒ…ç»ªç¬é—´\n- ä¿æŒç®€æ´ä½†è§†è§‰å†²å‡»åŠ›å¼º"
  : durationSeconds <= 8
    ? "- 0-2ç§’ï¼šå»ºç«‹åˆå§‹çŠ¶æ€\n- 2-6ç§’ï¼šä¸»è¦åŠ¨ä½œ/æƒ…ç»ªå‘å±•\n- 6-8ç§’ï¼šè‡ªç„¶æ”¶å°¾"
    : "- 0-3ç§’ï¼šåœºæ™¯å»ºç«‹\n- 3-8ç§’ï¼šåŠ¨ä½œå‘å±•\n- 8-12ç§’ï¼šæ”¶å°¾"}

å…·ä½“æè¿°ï¼š
- **ä¸»ä½“åŠ¨ä½œ**ï¼šè¡¨æƒ…å˜åŒ–ã€çœ¼ç¥ã€è‚¢ä½“åŠ¨ä½œã€æ‰‹åŠ¿
- **å¾®åŠ¨æ€**ï¼šå‘¼å¸èµ·ä¼ã€çœ¨çœ¼ã€å˜´å”‡å¾®åŠ¨ã€å¤´å‘é£˜åŠ¨
- **ç‰©ç†æ•ˆæœ**ï¼šè¡£ç‰©æ‘†åŠ¨ã€æè´¨åå°„ã€å…‰å½±å˜åŒ–

## 5. Mood æƒ…ç»ªæ°›å›´
- æ•´ä½“æƒ…ç»ªåŸºè°ƒ
- å¿ƒç†æš—ç¤ºï¼ˆä¸»ä½“åœ¨æƒ³ä»€ä¹ˆ/æ„Ÿå—ä»€ä¹ˆï¼‰
- æƒ…ç»ªå¼§çº¿ï¼ˆä»ä»€ä¹ˆçŠ¶æ€åˆ°ä»€ä¹ˆçŠ¶æ€ï¼‰

è¯·ç”¨ä¸­æ–‡è¯¦ç»†æè¿°ï¼Œåƒç»™ä¸“ä¸šæ‘„å½±å›¢é˜Ÿåš briefing ä¸€æ ·å…·ä½“ã€‚`,
                },
              ],
            },
          ],
        });

        for await (const event of analysisStream) {
          if (event.type === "content_block_delta" && event.delta.type === "text_delta") {
            const chunk = event.delta.text;
            imageAnalysis += chunk;
            await sendEvent({ type: "analysis_chunk", chunk });
          }
        }

        await sendEvent({ type: "analysis_end" });

        await sendEvent({
          type: "status",
          step: "âœ¨ æ­£åœ¨ç”Ÿæˆ Sora 2 æç¤ºè¯...",
          progress: 60,
        });
      } else {
        // æ— å›¾ç‰‡æ¨¡å¼ï¼šå…ˆåˆ†æç”¨æˆ·éœ€æ±‚ï¼Œæµå¼å±•ç¤ºæ€è€ƒè¿‡ç¨‹
        await sendEvent({
          type: "status",
          step: "ğŸ¬ AI æ­£åœ¨æ„æ€è§†é¢‘ç”»é¢...",
          progress: 10,
        });

        await sendEvent({ type: "analysis_start" });

        // æµå¼åˆ†æç”¨æˆ·éœ€æ±‚ï¼ˆåŸºäº Sora 2 Cookbook å®˜æ–¹æœ€ä½³å®è·µï¼‰
        const thinkingStream = anthropic.messages.stream({
          model: CLAUDE_LIGHT_MODEL,
          max_tokens: CLAUDE_LIGHT_MAX_TOKENS,
          messages: [
            {
              role: "user",
              content: `ä½ æ˜¯ä¸€ä½ä¸“ä¸šç”µå½±æ‘„å½±å¸ˆï¼Œæ­£åœ¨ä¸º Sora 2 è§†é¢‘ç”Ÿæˆè®¾è®¡ä¸€ä¸ª ${durationSeconds} ç§’çš„è§†é¢‘ç”»é¢ã€‚
åƒç»™æ‘„å½±å›¢é˜Ÿåš briefing ä¸€æ ·ï¼ŒåŸºäºç”¨æˆ·çš„æƒ³æ³•æ„å»ºå®Œæ•´çš„è§†è§‰æ–¹æ¡ˆã€‚

ç”¨æˆ·çš„åˆ›æ„æƒ³æ³•ï¼š${userRequest}

è¯·æŒ‰ä»¥ä¸‹ Sora 2 å®˜æ–¹æ¨èç»“æ„è®¾è®¡ï¼š

## 1. Style é£æ ¼å®šä½
- ç”µå½±é£æ ¼/å¹´ä»£æ„Ÿï¼ˆç°ä»£ã€å¤å¤èƒ¶ç‰‡ã€ç§‘å¹»ã€çºªå½•ç‰‡ç­‰ï¼‰
- è§†è§‰ç¾å­¦ï¼ˆè‰²è°ƒã€è´¨æ„Ÿã€æ•´ä½“æ°›å›´ï¼‰
- é£æ ¼å‚è€ƒï¼ˆå¦‚æœ‰é€‚åˆçš„ç”µå½±/å¯¼æ¼”é£æ ¼ï¼‰

## 2. Scene åœºæ™¯è®¾è®¡
- **ç¯å¢ƒ**ï¼šå…·ä½“åœ°ç‚¹ç±»å‹ã€æ—¶é—´ï¼ˆç™½å¤©/é»„é‡‘æ—¶æ®µ/å¤œæ™š/è“è°ƒæ—¶åˆ»ï¼‰
- **ä¸»ä½“**ï¼šäººç‰©/ç‰©ä½“çš„è¯¦ç»†å¤–è§‚ï¼ˆå¹´é¾„ã€æœè£…ã€å‘å‹ã€æè´¨ã€é¢œè‰²ï¼‰
- **ç©ºé—´å±‚æ¬¡**ï¼šå‰æ™¯ã€ä¸­æ™¯ã€èƒŒæ™¯å„å®‰æ’ä»€ä¹ˆå…ƒç´ 
- **æ°›å›´ç»†èŠ‚**ï¼šå¤©æ°”ã€æ¸©åº¦æ„Ÿã€ç¯å¢ƒç²’å­ï¼ˆç°å°˜/é›¨æ»´/è½å¶/å…‰æ–‘ç­‰ï¼‰

## 3. Cinematography æ‘„å½±è®¾è®¡
- **Camera æœºä½**ï¼šæ™¯åˆ«ï¼ˆwide establishing / medium / close-up / extreme close-upï¼‰
- **Lens é•œå¤´**ï¼šç„¦è·ï¼ˆ24mmå¹¿è§’/35mm/50mmæ ‡å‡†/85mmäººåƒ/135mmé•¿ç„¦ï¼‰
- **Angle è§’åº¦**ï¼šå¹³è§†(eye level)/ä½è§’åº¦(low angle)/é«˜è§’åº¦(high angle)
- **Movement è¿åŠ¨**ï¼šé™æ­¢/ç¼“æ…¢æ¨è¿›(slow dolly-in)/è·Ÿè¸ª(tracking)/æ¨ªæ‘‡(pan)/å‡é™(crane)
- **Depth æ™¯æ·±**ï¼šæµ…æ™¯æ·±è™šåŒ–èƒŒæ™¯ or æ·±æ™¯æ·±å±•ç¤ºç¯å¢ƒ
- **Lighting å…‰çº¿**ï¼šä¸»å…‰æ–¹å‘å’Œç±»å‹ã€è‰²æ¸©ã€è½¯ç¡¬å…‰è´¨æ„Ÿ

## 4. Actions åŠ¨ä½œæ—¶é—´çº¿ (${durationSeconds}ç§’)
${durationSeconds <= 4
  ? "**çŸ­ç‰‡èŠ‚å¥** - èšç„¦å•ä¸€åŠ¨ä½œæˆ–æƒ…ç»ªç¬é—´ï¼š\n- 0-1ç§’ï¼šå¿«é€Ÿå»ºç«‹ä¸»ä½“\n- 1-3ç§’ï¼šæ ¸å¿ƒåŠ¨ä½œ/è¡¨æƒ…\n- 3-4ç§’ï¼šå®šæ ¼æˆ–å¾®å¦™å˜åŒ–"
  : durationSeconds <= 8
    ? "**ä¸­ç­‰èŠ‚å¥** - åŒ…å«å®Œæ•´æƒ…ç»ªå¼§çº¿ï¼š\n- 0-2ç§’ï¼šå»ºç«‹åœºæ™¯ï¼Œä¸»ä½“åˆå§‹çŠ¶æ€\n- 2-5ç§’ï¼šä¸»è¦åŠ¨ä½œå±•å¼€ï¼Œæƒ…ç»ªå‘å±•\n- 5-8ç§’ï¼šæƒ…ç»ªé‡Šæ”¾æˆ–è‡ªç„¶æ”¶å°¾"
    : "**å™äº‹èŠ‚å¥** - æ„å»ºå®Œæ•´å°æ•…äº‹ï¼š\n- 0-3ç§’ï¼šåœºæ™¯å»ºç«‹ï¼Œäº¤ä»£ç¯å¢ƒ\n- 3-7ç§’ï¼šåŠ¨ä½œå‘å±•ï¼Œæƒ…ç»ªå˜åŒ–\n- 7-10ç§’ï¼šæƒ…èŠ‚æ¨è¿›\n- 10-12ç§’ï¼šé«˜æ½®æˆ–æ„å‘³æ·±é•¿çš„ç»“å°¾"}

å…·ä½“åŠ¨ä½œè®¾è®¡ï¼š
- **ä¸»ä½“åŠ¨ä½œ**ï¼šè¡¨æƒ…å˜åŒ–ã€çœ¼ç¥ç§»åŠ¨ã€è‚¢ä½“è¯­è¨€ã€æ‰‹åŠ¿
- **å¾®åŠ¨æ€**ï¼šå‘¼å¸ã€çœ¨çœ¼ã€å˜´å”‡å¾®åŠ¨ã€å‘ä¸é£˜åŠ¨
- **ç‰©ç†æ•ˆæœ**ï¼šè¡£ç‰©éšåŠ¨ä½œæ‘†åŠ¨ã€æè´¨åå…‰ã€ç¯å¢ƒå…‰å½±å˜åŒ–

## 5. Mood æƒ…ç»ªæ°›å›´
- æ•´ä½“æƒ…ç»ªåŸºè°ƒï¼ˆæ¸©æš–/å†·å³»/ç¥ç§˜/æµªæ¼«/ç´§å¼ ç­‰ï¼‰
- å¿ƒç†æš—ç¤ºï¼ˆä¸»ä½“çš„å†…å¿ƒçŠ¶æ€ï¼‰
- æƒ…ç»ªå¼§çº¿ï¼ˆä»___åˆ°___çš„å˜åŒ–ï¼‰

è¯·ç”¨ä¸­æ–‡è¯¦ç»†è®¾è®¡ï¼Œè¿™äº›ä¿¡æ¯å°†ç”¨äºç”Ÿæˆä¸“ä¸šçš„ Sora 2 æç¤ºè¯ã€‚`,
            },
          ],
        });

        for await (const event of thinkingStream) {
          if (event.type === "content_block_delta" && event.delta.type === "text_delta") {
            const chunk = event.delta.text;
            imageAnalysis += chunk;
            await sendEvent({ type: "analysis_chunk", chunk });
          }
        }

        await sendEvent({ type: "analysis_end" });

        await sendEvent({
          type: "status",
          step: "âœ¨ æ­£åœ¨ç”Ÿæˆä¸“ä¸šæç¤ºè¯...",
          progress: 60,
        });
      }

      // ç¬¬äºŒé˜¶æ®µï¼šç”Ÿæˆ Sora 2 è§†é¢‘æç¤ºè¯ï¼ˆåŸºäº OpenAI Cookbook å®˜æ–¹ç»“æ„ï¼‰
      const durationGuide = getDurationGuide(durationSeconds);

      // ç»Ÿä¸€çš„ Sora 2 Cookbook æç¤ºè¯ç”Ÿæˆæ¨¡æ¿
      const promptSystemMessage = `You are an expert cinematographer crafting prompts for OpenAI Sora 2.
Your task is to write prompts as if briefing a professional film crew.

## Your Analysis:
${imageAnalysis}

## User's Creative Idea: ${userRequest}
## Video Duration: ${durationSeconds} seconds

${durationGuide}

## SORA 2 COOKBOOK PROMPT STRUCTURE

Write the prompt following this official structure (combine into flowing prose):

**1. Style (å¼€å¤´)**
Film era/aesthetic, visual style, color grade, texture.
Examples: "Style: 1970s romantic drama, shot on 35mm film with natural flares, soft focus, and warm halation"

**2. Scene Description (ä¸»ä½“)**
- Setting: specific location, time of day, weather, atmosphere
- Subject: detailed appearance (clothing, hair, expression, pose)
- Environment: foreground/background elements, spatial depth
- Ambient details: particles, reflections, environmental motion

**3. Cinematography (æŠ€æœ¯)**
- Camera: shot type (wide/medium/close-up), angle (eye level/low/high)
- Lens: focal length (24mm/35mm/50mm/85mm), depth of field
- Movement: static, dolly-in, tracking, pan, crane
- Lighting: key light direction, color temperature, quality (soft/hard)

**4. Actions (åŠ¨æ€)**
Describe what happens over ${durationSeconds} seconds:
- Character actions and movements
- Micro-details: breathing, blinking, hair movement, fabric motion
- Physics: material behavior, wind effects, light changes
${durationSeconds <= 4 ? "Focus on ONE key moment or gesture." : durationSeconds <= 8 ? "Include setup â†’ action â†’ subtle resolution." : "Include clear beginning â†’ development â†’ ending arc."}

**5. Mood/Atmosphere (å¯é€‰)**
Emotional tone, psychological undertone.

## OFFICIAL SORA 2 EXAMPLE (reference style):
"Style: 1970s romantic drama, shot on 35 mm film with natural flares, soft focus, and warm halation. Slight gate weave and handheld micro-shake evoke vintage intimacy. At golden hour, a brick tenement rooftop transforms into a small stage. Laundry lines strung with white sheets sway in the wind, catching the last rays of sunlight. Strings of mismatched fairy bulbs hum faintly overhead. A young woman in a flowing red silk dress dances barefoot, curls glowing in the fading light. Her partner â€” sleeves rolled, suspenders loose â€” claps along, his smile wide and unguarded. Cinematography: Camera: medium-wide shot, slow dolly-in from eye level. Lens: 40 mm spherical; shallow focus to isolate the couple from skyline. Lighting: golden natural key with tungsten bounce. Mood: nostalgic, tender, cinematic. Actions: She spins; her dress flares, catching sunlight. He steps in, catches her hand, and dips her into shadow. Sheets drift across frame, briefly veiling the skyline before parting again."

## RULES:
- Write in present tense (what IS happening)
- Be specific about camera parameters (actual mm values, not vague terms)
- Include physics: wind, material behavior, light interaction
- Add micro-movements: breathing, blinking, hair sway, fabric motion
- Describe spatial relationships clearly
- Keep as ONE continuous shot (no cuts)
- Style should be PHOTOREALISTIC or CINEMATIC unless user requests otherwise

## OUTPUT:
Generate a professional Sora 2 prompt (120-200 words) in English.
Output ONLY the prompt text, no explanations or labels.`;

      const promptResponse = await anthropic.messages.create({
        model: CLAUDE_LIGHT_MODEL,
        max_tokens: CLAUDE_LIGHT_MAX_TOKENS,
        messages: [{ role: "user", content: promptSystemMessage }],
      });

      const textBlock = promptResponse.content.find(
        (block): block is Anthropic.TextBlock => block.type === "text"
      );

      const generatedPrompt = textBlock?.text?.trim() || userRequest;

      await sendEvent({
        type: "status",
        step: "âœ… Sora 2 æç¤ºè¯å·²å°±ç»ªï¼",
        progress: 100,
      });

      await sendEvent({
        type: "prompt_ready",
        prompt: generatedPrompt,
        analysis: imageAnalysis || undefined,
      });
    } catch (error) {
      console.error("Sora analyze error:", error);
      await sendEvent({
        type: "error",
        error: error instanceof Error ? error.message : "åˆ†æå¤±è´¥",
      });
    } finally {
      await writer.close();
    }
  })();

  return new Response(stream.readable, {
    headers: {
      "Content-Type": "text/event-stream",
      "Cache-Control": "no-cache",
      Connection: "keep-alive",
    },
  });
}

/**
 * æ ¹æ®æ—¶é•¿æä¾›ä¸“ä¸šçš„ Sora 2 åˆ›ä½œæŒ‡å¯¼
 * åŸºäº OpenAI Cookbook å®˜æ–¹æœ€ä½³å®è·µ
 */
function getDurationGuide(seconds: number): string {
  if (seconds <= 4) {
    return `## Duration: ${seconds}s â€” Single Moment

**Best For:** A glance, a gesture, a reaction, a single striking visual
**Approach:** One camera setup, one focused action, maximum visual impact

**Timing:**
- 0-1s: Establish subject in environment
- 1-3s: The key moment/action/expression
- 3-4s: Hold or subtle micro-movement

**Camera:** Static or minimal movement (gentle push-in works well)
**Physics:** Focus on 1-2 micro-details (hair sway, fabric ripple, light flicker)
**Avoid:** Complex sequences, multiple actions, camera movement changes`;
  } else if (seconds <= 8) {
    return `## Duration: ${seconds}s â€” Emotional Arc

**Best For:** Character moments, mood pieces, single emotional transition
**Approach:** Setup â†’ Development â†’ Subtle resolution

**Timing:**
- 0-2s: Establish scene and subject's initial state
- 2-5s: Primary action/emotion unfolds
- 5-8s: Resolution or new emotional state

**Camera:** One smooth movement allowed (slow dolly-in, gentle pan)
**Physics:** Environmental motion (wind, light shifts, ambient particles)
**Micro-details:** Breathing rhythm, blinking, hair/fabric response to movement
**Lens:** 50mm or 85mm for character focus, shallow depth of field`;
  } else {
    return `## Duration: ${seconds}s â€” Mini Narrative

**Best For:** Short scene with clear progression, beginning-middle-end
**Approach:** Full story arc with 2-3 distinct beats

**Timing:**
- 0-3s: Wide establishing shot, set the scene
- 3-7s: Action develops, emotional journey
- 7-10s: Climax or key turning point
- 10-12s: Resolution, final meaningful state

**Camera:** Can include smooth continuous movement or gentle reframe
**Storytelling:** Cause-and-effect, show character motivation through action
**Physics:** Complex interactions (multiple elements responding to environment)
**Depth:** Use foreground/background relationship to create visual interest
**Lens:** Start wide (35mm), can end tighter if following action`;
  }
}
