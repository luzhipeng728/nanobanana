import { NextRequest } from "next/server";
import Anthropic from "@anthropic-ai/sdk";
import { CLAUDE_LIGHT_MODEL, CLAUDE_LIGHT_MAX_TOKENS } from "@/lib/claude-config";

export interface SoraAnalyzeEvent {
  type: "status" | "analysis_start" | "analysis_chunk" | "analysis_end" | "prompt_ready" | "error";
  step?: string;
  progress?: number;
  chunk?: string;
  prompt?: string;
  analysis?: string;
  error?: string;
}

/**
 * Sora è§†é¢‘æ™ºèƒ½åˆ†æ API
 * 1. åˆ†æè¾“å…¥å›¾ç‰‡çš„å†…å®¹ã€äººç‰©ã€åœºæ™¯
 * 2. æ ¹æ®æ—¶é•¿ç”Ÿæˆè¯¦ç»†çš„è§†é¢‘æè¿°ï¼ˆåŒ…å«å¿ƒç†æ´»åŠ¨ã€è¡¨æƒ…å˜åŒ–ã€åŠ¨ä½œç»†èŠ‚ï¼‰
 */
export async function POST(request: NextRequest) {
  const encoder = new TextEncoder();

  const stream = new TransformStream();
  const writer = stream.writable.getWriter();

  const sendEvent = async (event: SoraAnalyzeEvent) => {
    await writer.write(encoder.encode(`data: ${JSON.stringify(event)}\n\n`));
  };

  (async () => {
    try {
      const body = await request.json();
      const { userRequest, imageUrl, durationSeconds = 8 } = body as {
        userRequest: string;
        imageUrl?: string;
        durationSeconds?: number;
      };

      if (!userRequest) {
        await sendEvent({ type: "error", error: "è¯·è¾“å…¥è§†é¢‘æè¿°" });
        await writer.close();
        return;
      }

      const apiKey = process.env.ANTHROPIC_API_KEY;
      if (!apiKey) {
        await sendEvent({ type: "error", error: "ANTHROPIC_API_KEY æœªé…ç½®" });
        await writer.close();
        return;
      }

      const anthropic = new Anthropic({
        apiKey,
        baseURL: process.env.ANTHROPIC_BASE_URL || undefined,
      });

      let imageAnalysis = "";

      // ç¬¬ä¸€é˜¶æ®µï¼šè¯¦ç»†åˆ†æå›¾ç‰‡
      if (imageUrl) {
        await sendEvent({
          type: "status",
          step: "ğŸ‘ï¸ AI æ­£åœ¨åˆ†æå›¾ç‰‡å†…å®¹...",
          progress: 10,
        });

        await sendEvent({ type: "analysis_start" });

        // æ„å»ºå›¾ç‰‡å†…å®¹
        const imageContent: Anthropic.ImageBlockParam[] = [];
        if (imageUrl.startsWith("data:")) {
          const match = imageUrl.match(/^data:([^;]+);base64,(.+)$/);
          if (match) {
            imageContent.push({
              type: "image",
              source: {
                type: "base64",
                media_type: match[1] as "image/jpeg" | "image/png" | "image/gif" | "image/webp",
                data: match[2],
              },
            });
          }
        } else {
          imageContent.push({
            type: "image",
            source: {
              type: "url",
              url: imageUrl,
            },
          });
        }

        // æµå¼åˆ†æå›¾ç‰‡ - æ”¯æŒåˆ†é•œå›¾è¯†åˆ«
        const analysisStream = anthropic.messages.stream({
          model: CLAUDE_LIGHT_MODEL,
          max_tokens: CLAUDE_LIGHT_MAX_TOKENS,
          messages: [
            {
              role: "user",
              content: [
                ...imageContent,
                {
                  type: "text",
                  text: `è¯·ä»”ç»†åˆ†æè¿™å¼ å›¾ç‰‡ï¼Œä¸º Sora è§†é¢‘ç”Ÿæˆåšå‡†å¤‡ã€‚

ç”¨æˆ·çš„åˆ›æ„æƒ³æ³•ï¼š${userRequest}
è§†é¢‘æ—¶é•¿ï¼š${durationSeconds} ç§’

**é¦–å…ˆåˆ¤æ–­ï¼šè¿™æ˜¯åˆ†é•œå›¾ï¼ˆStoryboardï¼‰è¿˜æ˜¯å•å¼ å›¾ç‰‡ï¼Ÿ**

---

## å¦‚æœæ˜¯ã€åˆ†é•œå›¾ã€‘ï¼ˆå¤šä¸ªç”»é¢/é¢æ¿ï¼‰ï¼š

è¯·æŒ‰ç…§åˆ†é•œé¡ºåºä¾æ¬¡æè¿°ï¼š

### åˆ†é•œ 1 (ç¬¬Xç§’)
- ç”»é¢å†…å®¹
- äººç‰©åŠ¨ä½œ/è¡¨æƒ…
- é•œå¤´è¿åŠ¨ï¼ˆæ¨ã€æ‹‰ã€æ‘‡ã€ç§»ç­‰ï¼‰
- æƒ…ç»ª/æ°›å›´

### åˆ†é•œ 2 (ç¬¬Xç§’)
...ä»¥æ­¤ç±»æ¨

**æ—¶é—´åˆ†é…å»ºè®®**ï¼šæ ¹æ® ${durationSeconds} ç§’æ€»æ—¶é•¿ï¼Œåˆç†åˆ†é…æ¯ä¸ªåˆ†é•œçš„æ—¶é—´ã€‚

---

## å¦‚æœæ˜¯ã€å•å¼ å›¾ç‰‡ã€‘ï¼š

### 1. äººç‰©/ä¸»ä½“åˆ†æ
- å¤–è²Œç‰¹å¾ï¼ˆå¹´é¾„ã€æ€§åˆ«ã€å‘å‹ã€æœè£…é£æ ¼ï¼‰
- å½“å‰å§¿æ€å’Œè¡¨æƒ…
- å¯èƒ½çš„æ€§æ ¼ç‰¹ç‚¹å’Œæƒ…ç»ªçŠ¶æ€

### 2. åœºæ™¯ç¯å¢ƒ
- åœ°ç‚¹å’Œæ—¶é—´ï¼ˆå®¤å†…/å®¤å¤–ã€ç™½å¤©/å¤œæ™šï¼‰
- èƒŒæ™¯å…ƒç´ å’Œæ°›å›´
- å…‰çº¿æ¡ä»¶å’Œè‰²è°ƒ

### 3. åŠ¨æ€åŒ–å»ºè®®
- äººç‰©å¯ä»¥åšçš„åŠ¨ä½œåºåˆ—
- å¤´å‘ã€è¡£æœç­‰åŠ¨æ€æ•ˆæœ
- èƒŒæ™¯ä¸­å¯ä»¥è¿åŠ¨çš„å…ƒç´ 

### 4. å¿ƒç†å’Œæƒ…æ„Ÿ
- åŸºäºè¡¨æƒ…æ¨æµ‹çš„å†…å¿ƒç‹¬ç™½
- æƒ…ç»ªå˜åŒ–è½¨è¿¹
- ä¸ç”¨æˆ·åˆ›æ„çš„ç»“åˆ

---

è¯·ç”¨ä¸­æ–‡è¯¦ç»†æè¿°ï¼Œè¿™äº›ä¿¡æ¯ä¼šå¸®åŠ©ç”Ÿæˆç”µå½±çº§çš„è§†é¢‘æè¿°ã€‚`,
                },
              ],
            },
          ],
        });

        for await (const event of analysisStream) {
          if (event.type === "content_block_delta" && event.delta.type === "text_delta") {
            const chunk = event.delta.text;
            imageAnalysis += chunk;
            await sendEvent({ type: "analysis_chunk", chunk });
          }
        }

        await sendEvent({ type: "analysis_end" });

        await sendEvent({
          type: "status",
          step: "âœ¨ æ­£åœ¨åˆ›ä½œè§†é¢‘å‰§æœ¬...",
          progress: 60,
        });
      } else {
        await sendEvent({
          type: "status",
          step: "ğŸ¬ æ­£åœ¨ç”Ÿæˆè§†é¢‘æè¿°...",
          progress: 30,
        });
      }

      // ç¬¬äºŒé˜¶æ®µï¼šç”Ÿæˆ Sora è§†é¢‘æç¤ºè¯
      const durationGuide = getDurationGuide(durationSeconds);

      // æ£€æµ‹æ˜¯å¦æ˜¯åˆ†é•œåˆ†æ
      const isStoryboard = imageAnalysis.includes("åˆ†é•œ") || imageAnalysis.includes("Storyboard") || imageAnalysis.includes("é¢æ¿");

      const promptSystemMessage = imageUrl
        ? `You are a professional video director creating prompts for OpenAI Sora.

## Image Analysis:
${imageAnalysis}

## User's Creative Idea: ${userRequest}
## Video Duration: ${durationSeconds} seconds
## Analysis Type: ${isStoryboard ? "STORYBOARD (Multiple Scenes)" : "Single Image"}

${durationGuide}

${isStoryboard ? `
## STORYBOARD MODE - CRITICAL:

The image contains a STORYBOARD with multiple panels/scenes.
You MUST create a continuous narrative that follows the storyboard sequence.

**Structure:**
- Describe the video as a flowing sequence matching the storyboard panels
- Use time markers to indicate transitions
- Maintain visual and emotional continuity between scenes
- Include camera movements that connect scenes (cuts, transitions, zooms)

**Example for storyboard:**
"Opening on a close-up of trembling hands gripping a letter (0-2s), pull back to reveal a young woman's tear-streaked face (2-4s). Cut to her walking down a rainy street, umbrella tilted against the wind (4-7s). Final shot: she looks up at the sky, a small smile breaking through as sunlight pierces the clouds (7-10s)."

Generate a sequential narrative (100-180 words) following the storyboard exactly.
` : `
## SINGLE IMAGE MODE:

**Structure your prompt with these elements:**
1. **Opening Scene** (0-2s): Establish the mood and initial state
2. **Main Action** (middle): The key movement or emotion
3. **Subtle Details**: Micro-expressions, hair movement, fabric motion
4. **Internal Thoughts**: What the subject might be thinking/feeling
5. **Atmospheric Elements**: Wind, light changes, ambient motion

**Example for 8s video:**
"A young woman with flowing auburn hair sits by a rain-streaked window, her eyes reflecting distant memories. She slowly turns her head, a gentle smile forming as if remembering something precious. Her fingers absently trace the condensation on the glass. The soft afternoon light catches the tears gathering in her eyes - not of sadness, but of bittersweet nostalgia. Outside, cherry blossoms drift past like scattered thoughts."

Generate a rich, emotional prompt (80-150 words) that brings this image to life.
`}

**IMPORTANT:**
- Write in present tense, describing what IS happening
- Include emotional undertones and psychological depth
- Add physical micro-details (blinking, breathing, slight movements)
- Describe the atmosphere and mood
- Keep it cinematic and evocative

Output ONLY the prompt text in English, nothing else.`
        : `You are a professional video director creating prompts for OpenAI Sora.

User's creative idea: ${userRequest}
Video Duration: ${durationSeconds} seconds

${durationGuide}

## Sora Text-to-Video Best Practices:

**Include these elements:**
1. **Subject**: Detailed description of who/what
2. **Setting**: Where and when, atmosphere
3. **Action**: What's happening, the motion
4. **Emotion**: The feeling and mood
5. **Details**: Small movements, environmental effects
6. **Camera**: Angle and movement suggestions

**Example:**
"A wise elderly craftsman with weathered hands carefully shapes a piece of glowing metal in his dimly lit workshop. Sparks dance around him like fireflies as he works with practiced precision. His eyes, crinkled with concentration, reflect decades of mastery. The warm orange glow of the forge illuminates dust particles floating in the air."

Generate a vivid, cinematic prompt (60-120 words).
Output ONLY the prompt text in English, nothing else.`;

      const promptResponse = await anthropic.messages.create({
        model: CLAUDE_LIGHT_MODEL,
        max_tokens: CLAUDE_LIGHT_MAX_TOKENS,
        messages: [{ role: "user", content: promptSystemMessage }],
      });

      const textBlock = promptResponse.content.find(
        (block): block is Anthropic.TextBlock => block.type === "text"
      );

      const generatedPrompt = textBlock?.text?.trim() || userRequest;

      await sendEvent({
        type: "status",
        step: "âœ… è§†é¢‘å‰§æœ¬åˆ›ä½œå®Œæˆï¼",
        progress: 100,
      });

      await sendEvent({
        type: "prompt_ready",
        prompt: generatedPrompt,
        analysis: imageAnalysis || undefined,
      });
    } catch (error) {
      console.error("Sora analyze error:", error);
      await sendEvent({
        type: "error",
        error: error instanceof Error ? error.message : "åˆ†æå¤±è´¥",
      });
    } finally {
      await writer.close();
    }
  })();

  return new Response(stream.readable, {
    headers: {
      "Content-Type": "text/event-stream",
      "Cache-Control": "no-cache",
      Connection: "keep-alive",
    },
  });
}

/**
 * æ ¹æ®æ—¶é•¿æä¾›ä¸åŒçš„åˆ›ä½œæŒ‡å¯¼
 */
function getDurationGuide(seconds: number): string {
  if (seconds <= 4) {
    return `## Duration Guide (${seconds}s - Short):
- Focus on ONE key moment or emotion
- Simple, impactful action
- Think of it as a perfect GIF or moment capture
- Example: A single glance, a smile forming, wind catching hair`;
  } else if (seconds <= 8) {
    return `## Duration Guide (${seconds}s - Medium):
- Allow for a small emotional arc
- Can include a subtle transition (e.g., neutral â†’ smile)
- Add environmental motion (wind, light shifts)
- Include micro-expressions and natural movements
- Example: Looking away pensively, then turning with a warm smile`;
  } else {
    return `## Duration Guide (${seconds}s - Extended):
- Create a mini narrative arc
- Multiple subtle emotion changes
- Include interaction with environment
- Build atmosphere over time
- Can include gentle camera movement
- Example: Starting distant in thought, then noticing something, reacting with wonder`;
  }
}
