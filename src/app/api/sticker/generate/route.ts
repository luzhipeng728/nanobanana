import { NextRequest } from "next/server";
import Anthropic from "@anthropic-ai/sdk";
import { v4 as uuidv4 } from "uuid";
import { prisma } from "@/lib/prisma";
import { generateImageAction } from "@/app/actions/generate";
import type { GeminiImageModel, ImageGenerationConfig } from "@/types/image-gen";

// åˆå§‹åŒ– Anthropic å®¢æˆ·ç«¯
function getAnthropicClient() {
  const apiKey = process.env.ANTHROPIC_API_KEY;
  if (!apiKey) {
    throw new Error("ANTHROPIC_API_KEY æœªé…ç½®");
  }
  return new Anthropic({
    apiKey,
    baseURL: process.env.ANTHROPIC_BASE_URL || undefined,
  });
}

// åˆ†æåŸå§‹å›¾ç‰‡ï¼Œè·å–åŸºç¡€æè¿°ï¼ˆæµå¼ï¼‰
async function analyzeOriginalImage(
  imageUrl: string,
  animationPrompt: string,
  onChunk: (chunk: string) => Promise<void>
): Promise<string> {
  const anthropic = getAnthropicClient();
  let analysisText = "";
  
  const stream = anthropic.messages.stream({
    model: "claude-sonnet-4-5-20250929",
    max_tokens: 1500,
    messages: [
      {
        role: "user",
        content: [
          {
            type: "image",
            source: { type: "url", url: imageUrl },
          },
          {
            type: "text",
            text: `Analyze this image carefully for creating a "${animationPrompt}" animation.

I need EXTREMELY DETAILED descriptions of STATIC elements that must remain UNCHANGED across all animation frames.

Please describe in English:

## 1. SUBJECT (EXACT details that must stay fixed):
- Face shape, skin tone, facial features (except expression)
- Hair: exact style, color, length, how it's arranged, any accessories
- Body pose: exact position of torso, shoulders, arms, hands
- Camera angle and distance from subject

## 2. CLOTHING & ACCESSORIES (EXACT details):
- Every piece of clothing with colors, patterns, textures
- All accessories: jewelry, glasses, hair clips, etc.
- How clothes are positioned/draped

## 3. BACKGROUND (EXACT details):
- Background color or gradient
- All elements present (if any)
- Lighting direction and quality

## 4. ART STYLE:
- Rendering style (photorealistic, anime, cartoon, etc.)
- Color palette and saturation
- Lighting quality and shadows

## 5. ANIMATION NOTES for "${animationPrompt}":
- What facial features should change (eyes, eyebrows, mouth, cheeks only)
- Suggest VERY SUBTLE progression (5-10% change per frame)
- Keep all other elements COMPLETELY STATIC

Output in clear English with bullet points.`,
          },
        ],
      },
    ],
  });

  for await (const event of stream) {
    if (event.type === "content_block_delta" && event.delta.type === "text_delta") {
      const chunk = event.delta.text;
      analysisText += chunk;
      await onChunk(chunk);
    }
  }

  return analysisText;
}

// ä¸€æ¬¡æ€§ç”Ÿæˆ 10 å¸§çš„æç¤ºè¯
async function generateAllFramePrompts(
  anthropic: Anthropic,
  baseAnalysis: string,
  animationPrompt: string
): Promise<string[]> {
  const response = await anthropic.messages.create({
    model: "claude-sonnet-4-5-20250929",
    max_tokens: 4000,
    messages: [{
      role: "user",
      content: `Based on this subject analysis, generate 10 image prompts for a "${animationPrompt}" animation sequence.

Subject Analysis:
${baseAnalysis.substring(0, 1200)}

## ABSOLUTE REQUIREMENTS FOR SMOOTH ANIMATION:

### 1. STATIC ELEMENTS (MUST BE IDENTICAL in ALL 10 prompts):
- Character's hair style, color, and arrangement
- Clothing and accessories (exact same items, colors, positions)
- Background (same color, same elements, same composition)
- Art style and rendering quality
- Lighting direction and color temperature
- Character's body pose and position (torso, shoulders, arms, hands)
- Camera angle and distance

### 2. ANIMATION RULES - ONLY FACE CHANGES:
- Animation "${animationPrompt}" should ONLY affect:
  * Eyes (shape, openness, direction)
  * Eyebrows (angle, height)
  * Mouth (shape, openness)
  * Cheeks (blush, puffing)
- NEVER change: hair, body, clothes, pose, background, camera angle

### 3. EXTREMELY SUBTLE TRANSITIONS:
- Each frame changes by only 5-10% from the previous frame
- Frame 1: Completely neutral face (baseline)
- Frames 2-4: Very gradual build-up (barely noticeable changes each frame)
- Frame 5-6: Peak expression (maximum but still natural)
- Frames 7-9: Very gradual return to neutral
- Frame 10: Nearly identical to Frame 1 (for smooth loop)

### 4. PROMPT STRUCTURE (use this exact format for each):
"[EXACT subject description from analysis], [EXACT clothing], [EXACT pose], [EXACT background], [EXACT art style], [SPECIFIC facial expression for this frame only]"

## OUTPUT FORMAT:
Generate EXACTLY 10 prompts, each 80-100 words, separated by "---":

Prompt 1:
[Complete prompt with neutral face - this is the baseline]
---
Prompt 2:
[Same as Prompt 1 but with 5% expression change]
---
...continue to Prompt 10...

REMEMBER: The viewer should see a smooth animation where ONLY the face subtly changes. Any change in hair, clothes, pose, or background will ruin the animation.`
    }],
  });

  const textBlock = response.content.find(b => b.type === "text");
  const fullText = textBlock?.type === "text" ? textBlock.text : "";
  
  // è§£æ 10 ä¸ª prompts
  const prompts: string[] = [];
  const parts = fullText.split("---");
  
  for (const part of parts) {
    // æå– "Prompt N:" åé¢çš„å†…å®¹
    const match = part.match(/Prompt \d+:?\s*([\s\S]*)/i);
    if (match && match[1]) {
      const prompt = match[1].trim();
      if (prompt.length > 20) {
        prompts.push(prompt);
      }
    }
  }
  
  // å¦‚æœè§£æå¤±è´¥ï¼Œç”¨ç®€å•åˆ†å‰²
  if (prompts.length < 10) {
    const simpleParts = fullText.split(/(?:Prompt \d+:?|---)/i).filter(p => p.trim().length > 20);
    for (let i = prompts.length; i < 10 && i < simpleParts.length; i++) {
      prompts.push(simpleParts[i].trim());
    }
  }
  
  // è¡¥å……ç¼ºå¤±çš„ prompts
  while (prompts.length < 10) {
    prompts.push(`Frame ${prompts.length + 1} of ${animationPrompt} animation, same subject and style`);
  }
  
  console.log(`[generateAllFramePrompts] Generated ${prompts.length} prompts`);
  return prompts.slice(0, 10);
}

export async function POST(request: NextRequest) {
  const encoder = new TextEncoder();
  const stream = new TransformStream();
  const writer = stream.writable.getWriter();

  const sendEvent = async (event: any) => {
    await writer.write(encoder.encode(`data: ${JSON.stringify(event)}\n\n`));
  };

  (async () => {
    try {
      const body = await request.json();
      const { referenceImage, animationPrompt, model, config } = body;

      if (!referenceImage) {
        await sendEvent({ type: "error", error: "ç¼ºå°‘å‚è€ƒå›¾ç‰‡" });
        await writer.close();
        return;
      }

      if (!animationPrompt) {
        await sendEvent({ type: "error", error: "ç¼ºå°‘åŠ¨ç”»æè¿°" });
        await writer.close();
        return;
      }

      const taskId = uuidv4();

      // Step 1: åˆ†æåŸå§‹å›¾ç‰‡ï¼ˆæµå¼æ˜¾ç¤ºï¼‰
      await sendEvent({
        type: "status",
        step: "ğŸ‘ï¸ Claude æ­£åœ¨åˆ†æå‚è€ƒå›¾ç‰‡...",
        progress: 5,
      });
      await sendEvent({ type: "claude_analysis_start" });

      let baseAnalysis = "";
      try {
        baseAnalysis = await analyzeOriginalImage(
          referenceImage,
          animationPrompt,
          async (chunk) => {
            await sendEvent({ type: "claude_analysis_chunk", chunk });
          }
        );
      } catch (err) {
        console.error("Analysis error:", err);
        await sendEvent({ type: "error", error: "å›¾ç‰‡åˆ†æå¤±è´¥" });
        await writer.close();
        return;
      }

      await sendEvent({ type: "claude_analysis_end" });

      // Step 2: åˆ›å»ºä»»åŠ¡è®°å½•
      await sendEvent({
        type: "status",
        step: "ğŸ“ åˆ›å»ºä»»åŠ¡...",
        progress: 15,
      });

      await prisma.stickerTask.create({
        data: {
          id: taskId,
          status: "processing",
          animationType: animationPrompt,
          referenceImage,
          model: model || "nano-banana",
          config: JSON.stringify(config || {}),
          customPrompt: baseAnalysis, // å­˜å‚¨åŸºç¡€åˆ†æ
          totalFrames: 10,
          completedFrames: 0,
          frames: JSON.stringify([]),
          frameStatuses: JSON.stringify(Array(10).fill("pending")),
        },
      });

      // Step 3: ç«‹å³åˆ›å»º StickerNode
      await sendEvent({
        type: "sticker_created",
        taskId,
      });

      await sendEvent({
        type: "status",
        step: "ğŸš€ ä»»åŠ¡å·²åˆ›å»ºï¼Œå¼€å§‹å¹¶å‘ç”Ÿæˆ 10 å¸§...",
        progress: 20,
      });

      // Step 4: åå°å¹¶å‘ç”Ÿæˆï¼ˆä¸ç­‰å¾…ï¼‰
      processParallelFrames(
        taskId,
        baseAnalysis,
        animationPrompt,
        referenceImage,
        (model || "nano-banana") as GeminiImageModel,
        config || {}
      ).catch((err) => {
        console.error(`[Sticker ${taskId}] Parallel generation error:`, err);
      });

      await sendEvent({
        type: "complete",
        progress: 100,
      });

      await writer.close();
    } catch (error) {
      console.error("Sticker generation error:", error);
      await sendEvent({
        type: "error",
        error: error instanceof Error ? error.message : "ç”Ÿæˆå¤±è´¥",
      });
      await writer.close();
    }
  })();

  return new Response(stream.readable, {
    headers: {
      "Content-Type": "text/event-stream",
      "Cache-Control": "no-cache",
      Connection: "keep-alive",
    },
  });
}

// å¸¦è¶…æ—¶çš„ Promise åŒ…è£…
function withTimeout<T>(promise: Promise<T>, timeoutMs: number, errorMessage: string): Promise<T> {
  return Promise.race([
    promise,
    new Promise<T>((_, reject) =>
      setTimeout(() => reject(new Error(errorMessage)), timeoutMs)
    ),
  ]);
}

// å¸¦é‡è¯•çš„å¼‚æ­¥å‡½æ•°æ‰§è¡Œå™¨
async function withRetry<T>(
  fn: () => Promise<T>,
  maxRetries: number = 3,
  delayMs: number = 2000,
  taskName: string = "operation"
): Promise<T> {
  let lastError: Error | null = null;
  
  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      return await fn();
    } catch (err) {
      lastError = err instanceof Error ? err : new Error(String(err));
      console.warn(`[Retry] ${taskName} attempt ${attempt}/${maxRetries} failed: ${lastError.message}`);
      
      if (attempt < maxRetries) {
        console.log(`[Retry] Waiting ${delayMs}ms before retry...`);
        await new Promise(resolve => setTimeout(resolve, delayMs));
        delayMs *= 1.5; // æŒ‡æ•°é€€é¿
      }
    }
  }
  
  throw lastError || new Error(`${taskName} failed after ${maxRetries} attempts`);
}

// åå°å¹¶å‘ç”Ÿæˆï¼šä¸€æ¬¡ç”Ÿæˆ 10 ä¸ª promptsï¼Œç„¶åå¹¶å‘ç”Ÿæˆå›¾ç‰‡
async function processParallelFrames(
  taskId: string,
  baseAnalysis: string,
  animationPrompt: string,
  originalReferenceImage: string,
  model: GeminiImageModel,
  config: ImageGenerationConfig
) {
  const anthropic = getAnthropicClient();
  const generatedFrames: (string | null)[] = Array(10).fill(null);
  const frameStatuses: string[] = Array(10).fill("pending");

  console.log(`[Sticker ${taskId}] Starting parallel generation...`);

  try {
    // Step 1: ä¸€æ¬¡æ€§ç”Ÿæˆ 10 ä¸ª prompts
    console.log(`[Sticker ${taskId}] Generating all 10 prompts...`);
    
    const framePrompts = await withRetry(
      () => withTimeout(
        generateAllFramePrompts(anthropic, baseAnalysis, animationPrompt),
        90000, // 90ç§’è¶…æ—¶
        "Claude prompt generation timeout"
      ),
      3,
      3000,
      "Generate all prompts"
    );
    
    console.log(`[Sticker ${taskId}] Got ${framePrompts.length} prompts, starting parallel image generation...`);
    
    // å­˜å‚¨ prompts åˆ°æ•°æ®åº“
    await prisma.stickerTask.update({
      where: { id: taskId },
      data: { customPrompt: JSON.stringify(framePrompts) },
    });

    // Step 2: 10 å¼ å›¾ç‰‡å…¨å¹¶å‘ç”Ÿæˆï¼ˆæ¯å¼ éƒ½ç”¨åŸå§‹å‚è€ƒå›¾ï¼‰
    // æ ‡è®°æ‰€æœ‰å¸§ä¸º generating
    for (let i = 0; i < 10; i++) {
      frameStatuses[i] = "generating";
    }
    await prisma.stickerTask.update({
      where: { id: taskId },
      data: { frameStatuses: JSON.stringify(frameStatuses) },
    });

    console.log(`[Sticker ${taskId}] Starting 10 concurrent image generations...`);

    // 10 ä¸ªå¹¶å‘è¯·æ±‚
    const allPromises = framePrompts.map((prompt, frameIndex) =>
      withRetry(
        () => withTimeout(
          generateImageAction(
            prompt,
            model,
            config,
            [originalReferenceImage] // æ¯å¸§éƒ½ç”¨åŒä¸€ä¸ªåŸå§‹å‚è€ƒå›¾ï¼
          ),
          120000, // 2åˆ†é’Ÿè¶…æ—¶
          `Frame ${frameIndex + 1} timeout`
        ),
        2, // é‡è¯• 2 æ¬¡
        2000,
        `Frame ${frameIndex + 1}`
      ).then(result => ({ frameIndex, result }))
       .catch(err => ({ frameIndex, error: err }))
    );

    // ç­‰å¾…æ‰€æœ‰å®Œæˆ
    const allResults = await Promise.all(allPromises);

    // å¤„ç†æ‰€æœ‰ç»“æœ
    for (const item of allResults) {
      const { frameIndex } = item;
      if ('result' in item && item.result.success && item.result.imageUrl) {
        generatedFrames[frameIndex] = item.result.imageUrl;
        frameStatuses[frameIndex] = "completed";
        console.log(`[Sticker ${taskId}] Frame ${frameIndex + 1} completed âœ“`);
      } else {
        frameStatuses[frameIndex] = "error";
        const errorMsg = 'error' in item ? item.error?.message : item.result?.error;
        console.error(`[Sticker ${taskId}] Frame ${frameIndex + 1} failed: ${errorMsg}`);
      }
    }

    // æ›´æ–°æ•°æ®åº“
    await prisma.stickerTask.update({
      where: { id: taskId },
      data: {
        frames: JSON.stringify(generatedFrames),
        frameStatuses: JSON.stringify(frameStatuses),
        completedFrames: frameStatuses.filter(s => s === "completed").length,
      },
    });

    console.log(`[Sticker ${taskId}] All 10 frames done, ${frameStatuses.filter(s => s === "completed").length}/10 completed`);
    
  } catch (err) {
    console.error(`[Sticker ${taskId}] Fatal error:`, err);
  }

  // æœ€ç»ˆçŠ¶æ€
  const completedCount = frameStatuses.filter(s => s === "completed").length;
  await prisma.stickerTask.update({
    where: { id: taskId },
    data: {
      status: completedCount >= 5 ? "completed" : "failed",
      frames: JSON.stringify(generatedFrames),
      frameStatuses: JSON.stringify(frameStatuses),
      completedFrames: completedCount,
      completedAt: new Date(),
    },
  });

  console.log(`[Sticker ${taskId}] âœ… Parallel generation finished (${completedCount}/10 frames)`);
}
