import { NextRequest } from "next/server";
import Anthropic from "@anthropic-ai/sdk";
import { v4 as uuidv4 } from "uuid";
import { prisma } from "@/lib/prisma";
import { generateImageAction } from "@/app/actions/generate";
import type { GeminiImageModel, ImageGenerationConfig } from "@/types/image-gen";

// åˆå§‹åŒ– Anthropic å®¢æˆ·ç«¯
function getAnthropicClient() {
  const apiKey = process.env.ANTHROPIC_API_KEY;
  if (!apiKey) {
    throw new Error("ANTHROPIC_API_KEY æœªé…ç½®");
  }
  return new Anthropic({
    apiKey,
    baseURL: process.env.ANTHROPIC_BASE_URL || undefined,
  });
}

// åˆ†æåŸå§‹å›¾ç‰‡ï¼Œè·å–åŸºç¡€æè¿°ï¼ˆæµå¼ï¼‰
async function analyzeOriginalImage(
  imageUrl: string,
  animationPrompt: string,
  onChunk: (chunk: string) => Promise<void>
): Promise<string> {
  const anthropic = getAnthropicClient();
  let analysisText = "";
  
  const stream = anthropic.messages.stream({
    model: "claude-sonnet-4-5-20250929",
    max_tokens: 1500,
    messages: [
      {
        role: "user",
        content: [
          {
            type: "image",
            source: { type: "url", url: imageUrl },
          },
          {
            type: "text",
            text: `Analyze this image carefully for creating a "${animationPrompt}" animation.

I need EXTREMELY DETAILED descriptions of STATIC elements that must remain UNCHANGED across all animation frames.

Please describe in English:

## 1. SUBJECT (EXACT details that must stay fixed):
- Face shape, skin tone, facial features (except expression)
- Hair: exact style, color, length, how it's arranged, any accessories
- Body pose: exact position of torso, shoulders, arms, hands
- Camera angle and distance from subject

## 2. CLOTHING & ACCESSORIES (EXACT details):
- Every piece of clothing with colors, patterns, textures
- All accessories: jewelry, glasses, hair clips, etc.
- How clothes are positioned/draped

## 3. BACKGROUND (EXACT details):
- Background color or gradient
- All elements present (if any)
- Lighting direction and quality

## 4. ART STYLE:
- Rendering style (photorealistic, anime, cartoon, etc.)
- Color palette and saturation
- Lighting quality and shadows

## 5. ANIMATION NOTES for "${animationPrompt}":
- What facial features should change (eyes, eyebrows, mouth, cheeks only)
- Suggest VERY SUBTLE progression (5-10% change per frame)
- Keep all other elements COMPLETELY STATIC

Output in clear English with bullet points.`,
          },
        ],
      },
    ],
  });

  for await (const event of stream) {
    if (event.type === "content_block_delta" && event.delta.type === "text_delta") {
      const chunk = event.delta.text;
      analysisText += chunk;
      await onChunk(chunk);
    }
  }

  return analysisText;
}

// ç”Ÿæˆæ¨¡æ¿ + è¡¨æƒ…å˜åŒ–çš„ç»“æ„åŒ–æ–¹æ³•
async function generateAllFramePrompts(
  anthropic: Anthropic,
  baseAnalysis: string,
  animationPrompt: string
): Promise<string[]> {
  const response = await anthropic.messages.create({
    model: "claude-sonnet-4-5-20250929",
    max_tokens: 3000,
    messages: [{
      role: "user",
      content: `Based on this image analysis, I need to create a "${animationPrompt}" sticker animation with 10 frames.

Image Analysis:
${baseAnalysis.substring(0, 1500)}

## CRITICAL REQUIREMENTS FOR STICKER ANIMATION:

### MANDATORY BACKGROUND:
- Background MUST be: **solid pure white (#FFFFFF)** or **solid light gray (#F5F5F5)**
- NO gradients, NO patterns, NO scenery, NO shadows on background
- This is for a sticker/emoji, clean background is essential

### MANDATORY CONSISTENCY (same in ALL frames):
- Exact same skin tone and color (no color shifts between frames)
- Exact same hair color, style, arrangement
- Exact same clothing colors and details
- Exact same lighting direction and intensity
- Exact same camera angle and framing

## YOUR TASK:
Generate a JSON with TWO parts:

### Part 1: BASE_TEMPLATE
Describe the subject for sticker use:
- Face shape, skin tone (be SPECIFIC about color, e.g., "fair peachy skin tone")
- Hair style/color/arrangement (EXACT details)
- Clothing with EXACT colors
- MUST include: "solid pure white background, no shadows, flat even lighting, sticker style, clean edges"
- Camera: head and shoulders portrait, centered

### Part 2: EXPRESSIONS array
10 SHORT facial expressions (10-15 words each) for "${animationPrompt}":
- Frame 1: Neutral baseline
- Frames 2-4: Subtle build-up (5% change each)
- Frames 5-6: Peak expression
- Frames 7-9: Return to neutral
- Frame 10: Match frame 1

Only describe: eyes, eyebrows, mouth, cheeks. NO other changes.

## OUTPUT (JSON only, no markdown):
{
  "base_template": "A young woman with long dark braided hair, fair peachy skin tone, wearing white V-neck blouse, solid pure white background, no shadows, flat even studio lighting, sticker style portrait, head and shoulders, centered composition, clean crisp edges",
  "expressions": [
    "neutral relaxed face, eyes forward, natural closed-lip smile",
    "eyes slightly brighter, mouth corners lifting 5%",
    "gentle smile forming, eyes softening",
    "warm smile, slight eye crinkle, faint blush",
    "full smile, eyes curved happily, rosy cheeks",
    "brightest smile, eyes squinted with joy, prominent blush",
    "smile softening, eyes still warm, blush fading",
    "returning to gentle smile, relaxed eyes",
    "soft pleasant look, nearly neutral",
    "neutral relaxed face, matching frame 1"
  ]
}

Output ONLY valid JSON.`
    }],
  });

  const textBlock = response.content.find(b => b.type === "text");
  const fullText = textBlock?.type === "text" ? textBlock.text : "";

  // è§£æ JSON å“åº”
  let baseTemplate = "";
  let expressions: string[] = [];

  try {
    // å°è¯•æå– JSONï¼ˆå¯èƒ½è¢« markdown åŒ…è£¹ï¼‰
    const jsonMatch = fullText.match(/\{[\s\S]*\}/);
    if (jsonMatch) {
      const parsed = JSON.parse(jsonMatch[0]);
      baseTemplate = parsed.base_template || "";
      expressions = parsed.expressions || [];
    }
  } catch (e) {
    console.error("[generateAllFramePrompts] Failed to parse JSON:", e);
  }

  // å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
  if (!baseTemplate || expressions.length < 10) {
    console.warn("[generateAllFramePrompts] Fallback to simple prompts");
    const fallbackPrompts: string[] = [];
    const expressionStages = [
      "neutral relaxed expression",
      "slightly brighter eyes, hint of smile",
      "gentle smile forming",
      "warm smile, eyes brightening",
      "full smile, eyes curved happily",
      "brightest expression, joyful smile",
      "smile softening",
      "returning to gentle expression",
      "nearly neutral, soft look",
      "neutral relaxed expression"
    ];

    for (let i = 0; i < 10; i++) {
      fallbackPrompts.push(`${baseAnalysis.substring(0, 300)}, ${expressionStages[i]}, consistent style and lighting`);
    }
    return fallbackPrompts;
  }

  // ç»„åˆåŸºç¡€æ¨¡æ¿å’Œè¡¨æƒ…ï¼Œç”Ÿæˆ 10 ä¸ªå®Œæ•´æç¤ºè¯
  const prompts: string[] = [];

  // å¼ºåˆ¶æ·»åŠ ä¸€è‡´æ€§çº¦æŸ
  const consistencySuffix = ", solid pure white background #FFFFFF, consistent skin tone, consistent lighting, sticker style, no background elements";

  for (let i = 0; i < 10; i++) {
    const expression = expressions[i] || expressions[expressions.length - 1] || "neutral expression";
    // å°†åŸºç¡€æ¨¡æ¿å’Œè¡¨æƒ…ç»„åˆï¼Œç¡®ä¿é™æ€éƒ¨åˆ†å®Œå…¨ä¸€è‡´
    const fullPrompt = `${baseTemplate}, ${expression}${consistencySuffix}`;
    prompts.push(fullPrompt);
  }

  console.log(`[generateAllFramePrompts] Generated ${prompts.length} prompts with template method`);
  console.log(`[generateAllFramePrompts] Base template: ${baseTemplate.substring(0, 100)}...`);

  return prompts;
}

export async function POST(request: NextRequest) {
  const encoder = new TextEncoder();
  const stream = new TransformStream();
  const writer = stream.writable.getWriter();

  const sendEvent = async (event: any) => {
    await writer.write(encoder.encode(`data: ${JSON.stringify(event)}\n\n`));
  };

  (async () => {
    try {
      const body = await request.json();
      const { referenceImage, animationPrompt, model, config } = body;

      if (!referenceImage) {
        await sendEvent({ type: "error", error: "ç¼ºå°‘å‚è€ƒå›¾ç‰‡" });
        await writer.close();
        return;
      }

      if (!animationPrompt) {
        await sendEvent({ type: "error", error: "ç¼ºå°‘åŠ¨ç”»æè¿°" });
        await writer.close();
        return;
      }

      const taskId = uuidv4();

      // Step 1: åˆ†æåŸå§‹å›¾ç‰‡ï¼ˆæµå¼æ˜¾ç¤ºï¼‰
      await sendEvent({
        type: "status",
        step: "ğŸ‘ï¸ Claude æ­£åœ¨åˆ†æå‚è€ƒå›¾ç‰‡...",
        progress: 5,
      });
      await sendEvent({ type: "claude_analysis_start" });

      let baseAnalysis = "";
      try {
        baseAnalysis = await analyzeOriginalImage(
          referenceImage,
          animationPrompt,
          async (chunk) => {
            await sendEvent({ type: "claude_analysis_chunk", chunk });
          }
        );
      } catch (err) {
        console.error("Analysis error:", err);
        await sendEvent({ type: "error", error: "å›¾ç‰‡åˆ†æå¤±è´¥" });
        await writer.close();
        return;
      }

      await sendEvent({ type: "claude_analysis_end" });

      // Step 2: åˆ›å»ºä»»åŠ¡è®°å½•
      await sendEvent({
        type: "status",
        step: "ğŸ“ åˆ›å»ºä»»åŠ¡...",
        progress: 15,
      });

      await prisma.stickerTask.create({
        data: {
          id: taskId,
          status: "processing",
          animationType: animationPrompt,
          referenceImage,
          model: model || "nano-banana",
          config: JSON.stringify(config || {}),
          customPrompt: baseAnalysis, // å­˜å‚¨åŸºç¡€åˆ†æ
          totalFrames: 10,
          completedFrames: 0,
          frames: JSON.stringify([]),
          frameStatuses: JSON.stringify(Array(10).fill("pending")),
        },
      });

      // Step 3: ç«‹å³åˆ›å»º StickerNode
      await sendEvent({
        type: "sticker_created",
        taskId,
      });

      await sendEvent({
        type: "status",
        step: "ğŸš€ ä»»åŠ¡å·²åˆ›å»ºï¼Œå¼€å§‹å¹¶å‘ç”Ÿæˆ 10 å¸§...",
        progress: 20,
      });

      // Step 4: åå°å¹¶å‘ç”Ÿæˆï¼ˆä¸ç­‰å¾…ï¼‰
      processParallelFrames(
        taskId,
        baseAnalysis,
        animationPrompt,
        referenceImage,
        (model || "nano-banana") as GeminiImageModel,
        config || {}
      ).catch((err) => {
        console.error(`[Sticker ${taskId}] Parallel generation error:`, err);
      });

      await sendEvent({
        type: "complete",
        progress: 100,
      });

      await writer.close();
    } catch (error) {
      console.error("Sticker generation error:", error);
      await sendEvent({
        type: "error",
        error: error instanceof Error ? error.message : "ç”Ÿæˆå¤±è´¥",
      });
      await writer.close();
    }
  })();

  return new Response(stream.readable, {
    headers: {
      "Content-Type": "text/event-stream",
      "Cache-Control": "no-cache",
      Connection: "keep-alive",
    },
  });
}

// å¸¦è¶…æ—¶çš„ Promise åŒ…è£…
function withTimeout<T>(promise: Promise<T>, timeoutMs: number, errorMessage: string): Promise<T> {
  return Promise.race([
    promise,
    new Promise<T>((_, reject) =>
      setTimeout(() => reject(new Error(errorMessage)), timeoutMs)
    ),
  ]);
}

// å¸¦é‡è¯•çš„å¼‚æ­¥å‡½æ•°æ‰§è¡Œå™¨
async function withRetry<T>(
  fn: () => Promise<T>,
  maxRetries: number = 3,
  delayMs: number = 2000,
  taskName: string = "operation"
): Promise<T> {
  let lastError: Error | null = null;
  
  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      return await fn();
    } catch (err) {
      lastError = err instanceof Error ? err : new Error(String(err));
      console.warn(`[Retry] ${taskName} attempt ${attempt}/${maxRetries} failed: ${lastError.message}`);
      
      if (attempt < maxRetries) {
        console.log(`[Retry] Waiting ${delayMs}ms before retry...`);
        await new Promise(resolve => setTimeout(resolve, delayMs));
        delayMs *= 1.5; // æŒ‡æ•°é€€é¿
      }
    }
  }
  
  throw lastError || new Error(`${taskName} failed after ${maxRetries} attempts`);
}

// åå°å¹¶å‘ç”Ÿæˆï¼šä¸€æ¬¡ç”Ÿæˆ 10 ä¸ª promptsï¼Œç„¶åå¹¶å‘ç”Ÿæˆå›¾ç‰‡
async function processParallelFrames(
  taskId: string,
  baseAnalysis: string,
  animationPrompt: string,
  originalReferenceImage: string,
  model: GeminiImageModel,
  config: ImageGenerationConfig
) {
  const anthropic = getAnthropicClient();
  const generatedFrames: (string | null)[] = Array(10).fill(null);
  const frameStatuses: string[] = Array(10).fill("pending");

  console.log(`[Sticker ${taskId}] Starting parallel generation with model: ${model}`);

  try {
    // Step 1: ä¸€æ¬¡æ€§ç”Ÿæˆ 10 ä¸ª prompts
    console.log(`[Sticker ${taskId}] Generating all 10 prompts...`);
    
    const framePrompts = await withRetry(
      () => withTimeout(
        generateAllFramePrompts(anthropic, baseAnalysis, animationPrompt),
        90000, // 90ç§’è¶…æ—¶
        "Claude prompt generation timeout"
      ),
      3,
      3000,
      "Generate all prompts"
    );
    
    console.log(`[Sticker ${taskId}] Got ${framePrompts.length} prompts, starting parallel image generation...`);
    
    // å­˜å‚¨ prompts åˆ°æ•°æ®åº“
    await prisma.stickerTask.update({
      where: { id: taskId },
      data: { customPrompt: JSON.stringify(framePrompts) },
    });

    // Step 2: 10 å¼ å›¾ç‰‡å…¨å¹¶å‘ç”Ÿæˆï¼ˆæ¯å¼ éƒ½ç”¨åŸå§‹å‚è€ƒå›¾ï¼‰
    // æ ‡è®°æ‰€æœ‰å¸§ä¸º generating
    for (let i = 0; i < 10; i++) {
      frameStatuses[i] = "generating";
    }
    await prisma.stickerTask.update({
      where: { id: taskId },
      data: { frameStatuses: JSON.stringify(frameStatuses) },
    });

    console.log(`[Sticker ${taskId}] Starting 10 concurrent image generations...`);

    // 10 ä¸ªå¹¶å‘è¯·æ±‚
    const allPromises = framePrompts.map((prompt, frameIndex) =>
      withRetry(
        () => withTimeout(
          generateImageAction(
            prompt,
            model,
            config,
            [originalReferenceImage] // æ¯å¸§éƒ½ç”¨åŒä¸€ä¸ªåŸå§‹å‚è€ƒå›¾ï¼
          ),
          120000, // 2åˆ†é’Ÿè¶…æ—¶
          `Frame ${frameIndex + 1} timeout`
        ),
        2, // é‡è¯• 2 æ¬¡
        2000,
        `Frame ${frameIndex + 1}`
      ).then(result => ({ frameIndex, result }))
       .catch(err => ({ frameIndex, error: err }))
    );

    // ç­‰å¾…æ‰€æœ‰å®Œæˆ
    const allResults = await Promise.all(allPromises);

    // å¤„ç†æ‰€æœ‰ç»“æœ
    for (const item of allResults) {
      const { frameIndex } = item;
      if ('result' in item && item.result.success && item.result.imageUrl) {
        generatedFrames[frameIndex] = item.result.imageUrl;
        frameStatuses[frameIndex] = "completed";
        console.log(`[Sticker ${taskId}] Frame ${frameIndex + 1} completed âœ“`);
      } else {
        frameStatuses[frameIndex] = "error";
        const errorMsg = 'error' in item ? item.error?.message : item.result?.error;
        console.error(`[Sticker ${taskId}] Frame ${frameIndex + 1} failed: ${errorMsg}`);
      }
    }

    // æ›´æ–°æ•°æ®åº“
    await prisma.stickerTask.update({
      where: { id: taskId },
      data: {
        frames: JSON.stringify(generatedFrames),
        frameStatuses: JSON.stringify(frameStatuses),
        completedFrames: frameStatuses.filter(s => s === "completed").length,
      },
    });

    console.log(`[Sticker ${taskId}] All 10 frames done, ${frameStatuses.filter(s => s === "completed").length}/10 completed`);
    
  } catch (err) {
    console.error(`[Sticker ${taskId}] Fatal error:`, err);
  }

  // æœ€ç»ˆçŠ¶æ€
  const completedCount = frameStatuses.filter(s => s === "completed").length;
  await prisma.stickerTask.update({
    where: { id: taskId },
    data: {
      status: completedCount >= 5 ? "completed" : "failed",
      frames: JSON.stringify(generatedFrames),
      frameStatuses: JSON.stringify(frameStatuses),
      completedFrames: completedCount,
      completedAt: new Date(),
    },
  });

  console.log(`[Sticker ${taskId}] âœ… Parallel generation finished (${completedCount}/10 frames)`);
}
