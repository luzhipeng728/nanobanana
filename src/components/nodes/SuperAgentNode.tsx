"use client";

import React, { useState, useCallback, useRef, useEffect, memo } from "react";
import { Handle, Position, NodeProps, useReactFlow, useStore } from "@xyflow/react";
import { useCanvas } from "@/contexts/CanvasContext";
import { enqueue, getQueueStatus } from "@/lib/rate-limiter";
import {
  Sparkles,
  Loader2,
  ChevronDown,
  ChevronUp,
  Search,
  Image as ImageIcon,
  XCircle,
  Copy,
  Brain,
  Link2,
  Eye,
  Palette,
  StopCircle,
  MessageSquare,
  Trash2,
  RotateCcw,
  AlertCircle,
} from "lucide-react";
import type {
  SuperAgentStreamEvent,
  ThoughtStep,
  FinalOutput,
  PromptItem,
} from "@/types/super-agent";
import { BaseNode } from "./BaseNode";
import { useImageModels, getDefaultModelId } from "@/hooks/useImageModels";
import { NodeTextarea, NodeButton, NodeLabel, NodeTabSelect } from "@/components/ui/NodeUI";
import {
  StreamingThought,
  AnimatedProgress,
  StepTimeline,
  PromptCard,
  SkillBadge,
  ThinkingIndicator,
} from "@/components/ui/StreamingUI";

// Tool names mapping (for step timeline)
const TOOL_NAMES: Record<string, string> = {
  skill_matcher: "åŒ¹é…æŠ€èƒ½",
  load_skill: "åŠ è½½æŠ€èƒ½",
  generate_prompt: "ç”Ÿæˆæç¤ºè¯",
  web_search: "æœç´¢èµ„æ–™",
  deep_research: "ğŸ”¬ æ·±åº¦ç ”ç©¶",  // æ–°çš„æ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“
  analyze_image: "åˆ†æå›¾ç‰‡",
  optimize_prompt: "ä¼˜åŒ–æç¤ºè¯",
  evaluate_prompt: "è´¨é‡è¯„ä¼°",
  finalize_output: "è¾“å‡ºç»“æœ",
};

// Extended PromptItem with status
interface PromptItemWithStatus extends PromptItem {
  status: "pending" | "generating" | "completed" | "error";
  taskId?: string;
  error?: string;
}

const SuperAgentNode = ({ data, id, isConnectable, selected }: NodeProps<any>) => {
  const { addImageNode, getConnectedImageNodes } = useCanvas();
  const { getNode: getReactFlowNode, getNodes: getReactFlowNodes } = useReactFlow();

  // è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
  const {
    models,
    isLoading: isLoadingModels,
    supportsReferenceImages,
    getSupportedResolutions,
    getSupportedAspectRatios,
  } = useImageModels();

  // States
  const [userRequest, setUserRequest] = useState(data.userRequest || "");
  const [isProcessing, setIsProcessing] = useState(false);
  const [thoughtSteps, setThoughtSteps] = useState<ThoughtStep[]>([]);
  const [currentIteration, setCurrentIteration] = useState(0);
  const [streamingThought, setStreamingThought] = useState(""); // å®æ—¶æµå¼æ€è€ƒå†…å®¹
  const [matchedSkill, setMatchedSkill] = useState<{
    id: string;
    name: string;
    confidence: number;
  } | null>(null);
  const [prompts, setPrompts] = useState<PromptItemWithStatus[]>([]);
  const [error, setError] = useState<string | null>(null);
  const [showDetails, setShowDetails] = useState(false);

  // Reference images with marker data
  const [connectedImages, setConnectedImages] = useState<string[]>([]);
  const [connectedImagesWithMarkers, setConnectedImagesWithMarkers] = useState<{
    imageUrl: string;
    markedImageUrl?: string;
    marksCount: number;
  }[]>([]);
  const [useForAnalysis, setUseForAnalysis] = useState(true);
  const [useForImageGen, setUseForImageGen] = useState(true);

  // Model selection
  const [selectedModel, setSelectedModel] = useState<string>("nano-banana-pro");
  const [imageSize, setImageSize] = useState<string>("2K");
  const [aspectRatio, setAspectRatio] = useState<string>("16:9");
  const [autoGenerate, setAutoGenerate] = useState(true);

  // å½“æ¨¡å‹åˆ—è¡¨åŠ è½½å®Œæˆåï¼Œè®¾ç½®é»˜è®¤æ¨¡å‹
  useEffect(() => {
    if (models.length > 0 && !data.model) {
      const defaultModel = getDefaultModelId(models);
      setSelectedModel(defaultModel);
    }
  }, [models, data.model]);

  // æ£€æŸ¥å½“å‰æ¨¡å‹æ˜¯å¦æ”¯æŒå‚è€ƒå›¾
  const currentModelSupportsRef = React.useMemo(() => {
    return supportsReferenceImages(selectedModel);
  }, [selectedModel, supportsReferenceImages]);

  // æ¨¡å‹é€‰é¡¹
  const modelOptions = React.useMemo(() => {
    return models.map(m => ({
      value: m.id,
      label: m.label,
    }));
  }, [models]);

  // å½“å‰æ¨¡å‹æ”¯æŒçš„åˆ†è¾¨ç‡å’Œæ¯”ä¾‹
  const supportedResolutions = React.useMemo(() => {
    return getSupportedResolutions(selectedModel);
  }, [selectedModel, getSupportedResolutions]);

  const supportedAspectRatios = React.useMemo(() => {
    return getSupportedAspectRatios(selectedModel);
  }, [selectedModel, getSupportedAspectRatios]);

  // åˆ†è¾¨ç‡é€‰é¡¹
  const resolutionOptions = React.useMemo(() => {
    return supportedResolutions.map(r => ({
      value: r,
      label: r,
    }));
  }, [supportedResolutions]);

  // æ¯”ä¾‹é€‰é¡¹
  const aspectRatioOptions = React.useMemo(() => {
    const labelMap: Record<string, string> = {
      '16:9': 'æ¨ªå±',
      '9:16': 'ç«–å±',
      '1:1': 'æ–¹å½¢',
      '4:3': '4:3',
      '3:4': '3:4',
    };
    return supportedAspectRatios.map(r => ({
      value: r,
      label: labelMap[r] || r,
    }));
  }, [supportedAspectRatios]);

  // å½“æ¨¡å‹å˜æ›´æ—¶ï¼Œæ ¡éªŒå¹¶é‡ç½®åˆ†è¾¨ç‡å’Œæ¯”ä¾‹
  useEffect(() => {
    if (supportedResolutions.length > 0 && !supportedResolutions.includes(imageSize)) {
      setImageSize(supportedResolutions[0]);
    }
  }, [selectedModel, supportedResolutions, imageSize]);

  useEffect(() => {
    if (supportedAspectRatios.length > 0 && !supportedAspectRatios.includes(aspectRatio)) {
      setAspectRatio(supportedAspectRatios[0]);
    }
  }, [selectedModel, supportedAspectRatios, aspectRatio]);

  // Deep research settings
  const [enableDeepResearch, setEnableDeepResearch] = useState(false);
  const [reasoningEffort, setReasoningEffort] = useState<'low' | 'medium' | 'high'>('low');

  // Multi-turn conversation state
  const [conversationId, setConversationId] = useState<string | null>(null);
  const [conversationTokens, setConversationTokens] = useState(0);
  const [hasCompressedHistory, setHasCompressedHistory] = useState(false);
  const [conversationHistory, setConversationHistory] = useState<Array<{
    role: 'user' | 'assistant';
    content: string;
    timestamp: number;
  }>>([]);

  // Generation state
  const [generatingCount, setGeneratingCount] = useState(0);
  const [progress, setProgress] = useState(0);

  // Refs
  const stepsContainerRef = useRef<HTMLDivElement>(null);
  const abortControllerRef = useRef<AbortController | null>(null);

  // Monitor edge changes
  const connectedEdgeCount = useStore((state) =>
    state.edges.filter((e) => e.target === id).length
  );

  // Get connected images with marker data
  useEffect(() => {
    const connectedNodes = getConnectedImageNodes(id);

    // Extract image URLs for display
    const imageUrls = connectedNodes
      .map(node => node.data.imageUrl)
      .filter((url): url is string => typeof url === 'string' && url.length > 0);
    setConnectedImages(imageUrls);

    // Extract images with marker data for generation
    const imagesWithMarkers = connectedNodes
      .filter(node => {
        const nodeData = node.data as { imageUrl?: string };
        return typeof nodeData.imageUrl === 'string' && nodeData.imageUrl.length > 0;
      })
      .map(node => {
        const nodeData = node.data as { imageUrl: string; markerData?: { markedImageUrl?: string; marks?: unknown[] } };
        return {
          imageUrl: nodeData.imageUrl,
          markedImageUrl: nodeData.markerData?.markedImageUrl,
          marksCount: nodeData.markerData?.marks?.length || 0,
        };
      });
    setConnectedImagesWithMarkers(imagesWithMarkers);
  }, [id, getConnectedImageNodes, connectedEdgeCount]);

  // Auto-scroll to latest step
  useEffect(() => {
    if (stepsContainerRef.current) {
      stepsContainerRef.current.scrollTop = stepsContainerRef.current.scrollHeight;
    }
  }, [thoughtSteps]);

  // Batch generate images
  const generateImagesInBatches = useCallback(async (promptsList: PromptItemWithStatus[]) => {
    const currentNode = getReactFlowNode(id);
    if (!currentNode) return;

    const NODE_WIDTH = 450;
    const NODE_HEIGHT = 500;
    const HORIZONTAL_GAP = 30;
    const VERTICAL_GAP = 30;

    // Position calculation
    const getNodePosition = (index: number) => {
      const allNodes = getReactFlowNodes();
      const column = Math.floor(index / 2);
      const row = index % 2;

      let startCol = 0;
      while (startCol < 100) {
        const testX = currentNode.position.x + 420 + startCol * (NODE_WIDTH + HORIZONTAL_GAP);
        const testY = currentNode.position.y;
        const occupied = allNodes.some((node) => {
          if (node.id === id) return false;
          const nodeWidth = (node.style?.width as number) || NODE_WIDTH;
          const nodeHeight = (node.style?.height as number) || NODE_HEIGHT;
          return (
            testX < node.position.x + nodeWidth &&
            testX + NODE_WIDTH > node.position.x &&
            testY < node.position.y + nodeHeight &&
            testY + NODE_HEIGHT > node.position.y
          );
        });
        if (!occupied) break;
        startCol++;
      }

      return {
        x: currentNode.position.x + 420 + (startCol + column) * (NODE_WIDTH + HORIZONTAL_GAP),
        y: currentNode.position.y + row * (NODE_HEIGHT + VERTICAL_GAP),
      };
    };

    let completedCount = 0;
    const totalCount = promptsList.length;

    // Queue all tasks
    const promises = promptsList.map((prompt, index) => {
      setPrompts((prev) =>
        prev.map((p) => (p.id === prompt.id ? { ...p, status: "pending" as const } : p))
      );

      return enqueue(selectedModel, async () => {
        try {
          setGeneratingCount((prev) => prev + 1);
          setPrompts((prev) =>
            prev.map((p) => (p.id === prompt.id ? { ...p, status: "generating" as const } : p))
          );

          // Build reference images array (include marked images if available)
          const referenceImagesForGen: string[] = [];
          if (useForImageGen) {
            connectedImagesWithMarkers.forEach(img => {
              referenceImagesForGen.push(img.imageUrl);
              // Include marked image if it has markers
              if (img.markedImageUrl && img.marksCount > 0) {
                referenceImagesForGen.push(img.markedImageUrl);
                console.log(`[SuperAgentNode] Including marked image with ${img.marksCount} markers`);
              }
            });
          }
          const config: any = {};
          if (referenceImagesForGen.length === 0) {
            config.aspectRatio = aspectRatio;
          }
          if (selectedModel === "nano-banana-pro") {
            config.imageSize = imageSize;
          }

          // éªŒè¯ prompt ä¸ä¸ºç©º
          if (!prompt.prompt || prompt.prompt.trim().length === 0) {
            console.error(`[SuperAgentNode] Empty prompt for scene "${prompt.scene}", skipping`);
            throw new Error(`åœºæ™¯ "${prompt.scene}" çš„æç¤ºè¯ä¸ºç©º`);
          }

          // æ£€æŸ¥æ˜¯å¦æœ‰å¸¦æ ‡è®°çš„å›¾ç‰‡
          const hasMarkers = connectedImagesWithMarkers.some(img => img.marksCount > 0);

          // å¦‚æœæœ‰æ ‡è®°ï¼Œåœ¨ prompt å‰é¢æ·»åŠ æ ‡è®°æ’é™¤æŒ‡ä»¤
          let finalPrompt = prompt.prompt;
          if (hasMarkers && useForImageGen) {
            const markerExclusionInstruction = `[CRITICAL INSTRUCTION - MUST FOLLOW]
The reference image contains RED CIRCLES with WHITE NUMBERS (â‘ â‘¡â‘¢...) as position markers for reference only.
These markers are NOT part of the actual image content.
YOU MUST NOT include any of the following in the generated image:
- Red circles or dots
- Numbers or digits (1, 2, 3, â‘ , â‘¡, â‘¢, etc.)
- Any circular markers or annotations
- Any text overlays or labels
Generate a CLEAN image as if the markers do not exist.
[END OF CRITICAL INSTRUCTION]

`;
            finalPrompt = markerExclusionInstruction + prompt.prompt;
            console.log(`[SuperAgentNode] Added marker exclusion instruction to prompt`);
          }

          console.log(`[SuperAgentNode] Generating image ${index + 1}: scene="${prompt.scene}", prompt="${finalPrompt.substring(0, 80)}..."`);

          const response = await fetch("/api/generate-image", {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({
              prompt: finalPrompt,
              model: selectedModel,
              config,
              referenceImages: referenceImagesForGen,
            }),
          });

          if (!response.ok) {
            const errorText = await response.text();
            console.error(`[SuperAgentNode] API error for scene "${prompt.scene}":`, errorText);
            throw new Error(`HTTP ${response.status}: ${response.statusText}`);
          }

          const result = await response.json();

          if (result.success && result.taskId) {
            const position = getNodePosition(index);
            addImageNode(
              undefined,
              prompt.prompt,
              position,
              result.taskId,
              { model: selectedModel, config, referenceImages: referenceImagesForGen },
              prompt.scene
            );

            setPrompts((prev) =>
              prev.map((p) =>
                p.id === prompt.id
                  ? { ...p, status: "completed" as const, taskId: result.taskId }
                  : p
              )
            );

            completedCount++;
            setProgress(90 + (completedCount / totalCount) * 10);
          }
        } catch (err) {
          setPrompts((prev) =>
            prev.map((p) =>
              p.id === prompt.id
                ? { ...p, status: "error" as const, error: err instanceof Error ? err.message : "ç”Ÿæˆå¤±è´¥" }
                : p
            )
          );
        } finally {
          setGeneratingCount((prev) => prev - 1);
        }
      });
    });

    await Promise.allSettled(promises);
    setProgress(100);
  }, [id, getReactFlowNode, getReactFlowNodes, addImageNode, connectedImagesWithMarkers, useForImageGen, selectedModel, aspectRatio, imageSize]);

  // Handle stream event
  const handleStreamEvent = useCallback((event: SuperAgentStreamEvent) => {
    switch (event.type) {
      case "start":
        setProgress(10);
        setStreamingThought(""); // æ¸…ç©ºæµå¼å†…å®¹
        break;

      case "skill_matched":
        setMatchedSkill({
          id: event.skillId,
          name: event.skillName,
          confidence: event.confidence,
        });
        setProgress(20);
        break;

      case "skill_not_matched":
        setMatchedSkill(null);
        break;

      // å®æ—¶æµå¼æ€è€ƒ chunk
      case "thinking_chunk":
        setCurrentIteration(event.iteration);
        setStreamingThought((prev) => prev + event.chunk);
        break;

      case "thought":
        setCurrentIteration(event.iteration);
        setProgress(Math.min(80, 20 + event.iteration * 10));
        setStreamingThought(""); // å®Œæ•´æ€è€ƒåˆ°è¾¾æ—¶æ¸…ç©ºæµå¼å†…å®¹
        setThoughtSteps((prev) => {
          const existing = prev.find((s) => s.iteration === event.iteration);
          if (existing) {
            return prev.map((s) =>
              s.iteration === event.iteration
                ? { ...s, thought: event.content }
                : s
            );
          }
          return [
            ...prev,
            {
              iteration: event.iteration,
              thought: event.content,
              action: "",
              actionInput: {},
              observation: "",
            },
          ];
        });
        break;

      case "action":
        setStreamingThought(""); // å·¥å…·è°ƒç”¨æ—¶æ¸…ç©º
        setThoughtSteps((prev) =>
          prev.map((s) =>
            s.iteration === event.iteration
              ? { ...s, action: event.tool, actionInput: event.input }
              : s
          )
        );
        break;

      // å·¥å…·è¾“å…¥ç”Ÿæˆæµå¼äº‹ä»¶ï¼ˆé˜²æ­¢é•¿å†…å®¹ç”Ÿæˆè¶…æ—¶ï¼‰
      case "tool_input_chunk":
        const chunkEvent = event as any;
        const toolDisplayName = TOOL_NAMES[chunkEvent.tool] || chunkEvent.tool;
        const sizeKB = (chunkEvent.totalSize / 1024).toFixed(1);
        // æ˜¾ç¤ºç”Ÿæˆè¿›åº¦ï¼Œè®©ç”¨æˆ·çŸ¥é“ç³»ç»Ÿåœ¨å·¥ä½œ
        setStreamingThought(`ğŸ“ ${toolDisplayName}... å·²ç”Ÿæˆ ${sizeKB}KB`);
        break;

      case "observation":
        setThoughtSteps((prev) =>
          prev.map((s) =>
            s.iteration === event.iteration
              ? { ...s, observation: JSON.stringify(event.result, null, 2) }
              : s
          )
        );
        break;

      // æ·±åº¦ç ”ç©¶äº‹ä»¶
      case "research_start":
        setStreamingThought(`ğŸ”¬ å¯åŠ¨æ·±åº¦ç ”ç©¶: ${(event as any).topic}`);
        break;

      case "research_progress":
        // æ˜¾ç¤ºæ›´è¯¦ç»†çš„è¿›åº¦ä¿¡æ¯
        const status = (event as any).status || `ç¬¬ ${event.round}/${event.maxRounds} è½®æœç´¢ä¸­...`;
        setStreamingThought(`ğŸ”¬ ${status}`);
        setProgress(Math.min(85, 30 + (event.round / event.maxRounds) * 50));
        break;

      case "research_evaluation":
        const evalEvent = event as any;
        setStreamingThought(
          `ğŸ“Š è¯„ä¼°ä¸­... è¦†ç›–ç‡: ${evalEvent.coverage?.toFixed(0) || 0}%` +
          (evalEvent.sufficient ? ' âœ… ä¿¡æ¯å……è¶³' : ' â³ ç»§ç»­æœç´¢')
        );
        break;

      case "research_complete":
        setStreamingThought(`âœ… ç ”ç©¶å®Œæˆï¼æ”¶é›†äº† ${event.coverage.toFixed(0)}% ä¿¡æ¯ï¼Œå…± ${event.rounds} è½®`);
        setProgress(85);
        break;

      case "search_result":
        // æ˜¾ç¤ºæœç´¢ç»“æœ
        setStreamingThought(`ğŸ” ${(event as any).summary}`);
        break;

      // æ·±åº¦ç ”ç©¶è¯¦ç»†äº‹ä»¶
      case "research_round_start":
        const roundStartEvent = event as any;
        setStreamingThought(`ğŸ”¬ ç¬¬ ${roundStartEvent.round}/${roundStartEvent.maxRounds} è½®å¼€å§‹ï¼Œ${roundStartEvent.queries?.length || 0} ä¸ªæŸ¥è¯¢`);
        break;

      case "research_search_start":
        setStreamingThought(`ğŸ” æœç´¢: ${(event as any).query}`);
        break;

      case "research_search_result":
        const searchResultEvent = event as any;
        setStreamingThought(`ğŸ“„ "${searchResultEvent.query?.substring(0, 20)}..." æ‰¾åˆ° ${searchResultEvent.resultsCount} æ¡ç»“æœ`);
        break;

      case "research_dedup":
        const dedupEvent = event as any;
        setStreamingThought(`ğŸ§¹ å»é‡: ${dedupEvent.before} â†’ ${dedupEvent.after} æ¡`);
        break;

      case "research_categorize_start":
        setStreamingThought(`ğŸ·ï¸ åˆ†ç±» ${(event as any).totalResults} æ¡ç»“æœ...`);
        break;

      case "research_categorize_batch":
        const batchEvent = event as any;
        setStreamingThought(`ğŸ·ï¸ åˆ†ç±»ä¸­ ${batchEvent.batch}/${batchEvent.total}...`);
        break;

      case "research_categorize_complete":
        setStreamingThought(`âœ… åˆ†ç±»å®Œæˆ: ${(event as any).totalCategorized} æ¡`);
        break;

      case "research_evaluation_start":
        setStreamingThought(`ğŸ“Š è¯„ä¼°ç¬¬ ${(event as any).round} è½®ç»“æœ...`);
        break;

      case "research_evaluation_rule":
        setStreamingThought(`ğŸ“ è§„åˆ™è¯„ä¼°: ${(event as any).ruleScore?.toFixed(0)}%`);
        break;

      case "research_evaluation_llm_start":
        setStreamingThought(`ğŸ¤– AI è¯„ä¼°ä¸­...`);
        break;

      case "research_evaluation_llm_complete":
        const llmCompleteEvent = event as any;
        setStreamingThought(`ğŸ¤– AI è¯„ä¼°: ${llmCompleteEvent.llmScore?.toFixed(0)}% | ç¼ºå¤±: ${llmCompleteEvent.missingInfo?.length || 0}`);
        break;

      case "research_plan_start":
        setStreamingThought(`ğŸ“‹ åˆ¶å®šæœç´¢è®¡åˆ’: ${(event as any).strategy} ç­–ç•¥`);
        break;

      case "research_plan_complete":
        setStreamingThought(`ğŸ“‹ è®¡åˆ’å®Œæˆ: ${(event as any).queriesCount} ä¸ªæŸ¥è¯¢`);
        break;

      case "research_report_start":
        setStreamingThought(`ğŸ“ ç”Ÿæˆç ”ç©¶æŠ¥å‘Š...`);
        break;

      case "research_report_summary_start":
        setStreamingThought(`âœï¸ ç”Ÿæˆæ‘˜è¦ä¸­...`);
        break;

      case "research_report_summary_complete":
        setStreamingThought(`âœ… æ‘˜è¦ç”Ÿæˆå®Œæˆ`);
        break;

      case "research_report_complete":
        setStreamingThought(`ğŸ“„ æŠ¥å‘Šç”Ÿæˆå®Œæˆ`);
        break;

      // LLM æµå¼è¾“å‡º
      case "research_summary_chunk":
        setStreamingThought((prev) => {
          const chunk = (event as any).chunk || '';
          // åªæ˜¾ç¤ºæœ€å 100 ä¸ªå­—ç¬¦
          const newText = prev + chunk;
          return `âœï¸ ${newText.slice(-100)}`;
        });
        break;

      case "complete":
        setProgress(90);
        setStreamingThought("");
        // Convert result prompts to PromptItemWithStatus
        const promptsWithStatus: PromptItemWithStatus[] = (event.result.prompts || []).map((p: PromptItem) => ({
          ...p,
          status: "pending" as const,
        }));
        setPrompts(promptsWithStatus);
        break;

      case "error":
        setError(event.error);
        setStreamingThought("");
        break;

      // Handle conversation state updates
      case "conversation_state":
        const convEvent = event as any;
        if (convEvent.conversationId) {
          setConversationId(convEvent.conversationId);
        }
        if (typeof convEvent.totalTokens === 'number') {
          setConversationTokens(convEvent.totalTokens);
        }
        if (typeof convEvent.hasCompressedHistory === 'boolean') {
          setHasCompressedHistory(convEvent.hasCompressedHistory);
        }
        break;
    }
  }, []);

  // Start generation
  const handleGenerate = useCallback(async () => {
    if (!userRequest.trim() || isProcessing) return;

    // ä¿å­˜ç”¨æˆ·è¯·æ±‚åˆ°å¯¹è¯å†å²
    const userMessage = {
      role: 'user' as const,
      content: userRequest,
      timestamp: Date.now(),
    };
    setConversationHistory(prev => [...prev, userMessage]);

    setIsProcessing(true);
    setThoughtSteps([]);
    setPrompts([]);
    setError(null);
    setMatchedSkill(null);
    setCurrentIteration(0);
    setProgress(0);

    abortControllerRef.current = new AbortController();

    try {
      // Build reference images for analysis (include marked images if available)
      const referenceImages: string[] = [];
      if (useForAnalysis && connectedImagesWithMarkers.length > 0) {
        connectedImagesWithMarkers.forEach(img => {
          referenceImages.push(img.imageUrl);
          // Include marked image if it has markers
          if (img.markedImageUrl && img.marksCount > 0) {
            referenceImages.push(img.markedImageUrl);
            console.log(`[SuperAgentNode] Including marked image for analysis with ${img.marksCount} markers`);
          }
        });
      }

      const response = await fetch("/api/super-agent", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          userRequest,
          referenceImages,
          enableDeepResearch,
          reasoningEffort: enableDeepResearch ? reasoningEffort : undefined,  // æ·±åº¦ç ”ç©¶å¼ºåº¦
          conversationId: conversationId || undefined,  // ä¼ é€’å¯¹è¯ ID
        }),
        signal: abortControllerRef.current.signal,
      });

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}`);
      }

      const reader = response.body?.getReader();
      if (!reader) {
        throw new Error("æ— æ³•è¯»å–å“åº”æµ");
      }

      const decoder = new TextDecoder();
      let buffer = "";
      let finalPrompts: PromptItemWithStatus[] = [];

      while (true) {
        const { done, value } = await reader.read();
        if (done) break;

        buffer += decoder.decode(value, { stream: true });
        const lines = buffer.split("\n");
        buffer = lines.pop() || "";

        for (const line of lines) {
          if (line.startsWith("data: ")) {
            try {
              const event: SuperAgentStreamEvent = JSON.parse(line.slice(6));
              handleStreamEvent(event);

              if (event.type === "complete") {
                console.log('[SuperAgentNode] Received prompts:', event.result.prompts);
                finalPrompts = (event.result.prompts || [])
                  .filter((p: PromptItem) => p.prompt && p.prompt.trim().length > 0)
                  .map((p: PromptItem) => ({
                    ...p,
                    status: "pending" as const,
                  }));
                console.log('[SuperAgentNode] Filtered prompts:', finalPrompts.length);
              }
            } catch (e) {
              console.warn("Failed to parse event:", line);
            }
          }
        }
      }

      // ä¿å­˜åŠ©æ‰‹å›å¤åˆ°å¯¹è¯å†å²
      if (finalPrompts.length > 0) {
        const assistantMessage = {
          role: 'assistant' as const,
          content: `ç”Ÿæˆäº† ${finalPrompts.length} ä¸ªåœºæ™¯æç¤ºè¯`,
          timestamp: Date.now(),
        };
        setConversationHistory(prev => [...prev, assistantMessage]);
      }

      // Auto-generate images
      if (autoGenerate && finalPrompts.length > 0) {
        setTimeout(() => {
          generateImagesInBatches(finalPrompts);
        }, 500);
      }

    } catch (err) {
      if (err instanceof Error && err.name === "AbortError") {
        console.log("Request aborted");
      } else {
        console.error("Generation failed:", err);
        setError(err instanceof Error ? err.message : "ç”Ÿæˆå¤±è´¥");
      }
    } finally {
      setIsProcessing(false);
    }
  }, [userRequest, connectedImagesWithMarkers, useForAnalysis, isProcessing, handleStreamEvent, autoGenerate, generateImagesInBatches, enableDeepResearch, reasoningEffort, conversationId]);

  // Stop generation
  const handleStop = useCallback(() => {
    if (abortControllerRef.current) {
      abortControllerRef.current.abort();
      setIsProcessing(false);
    }
  }, []);

  // Copy all prompts
  const handleCopyAll = useCallback(() => {
    const text = prompts.map(p => `ã€${p.scene}ã€‘\n${p.prompt}`).join('\n\n---\n\n');
    navigator.clipboard.writeText(text);
  }, [prompts]);

  // Manual generate single prompt
  const handleGenerateSingle = useCallback((prompt: PromptItemWithStatus) => {
    generateImagesInBatches([prompt]);
  }, [generateImagesInBatches]);

  // Clear conversation and start new
  const handleNewConversation = useCallback(() => {
    setConversationId(null);
    setConversationTokens(0);
    setHasCompressedHistory(false);
    setConversationHistory([]);
    setThoughtSteps([]);
    setPrompts([]);
    setError(null);
    setMatchedSkill(null);
    setProgress(0);
    setUserRequest("");
  }, []);

  return (
    <BaseNode
      title="Prompt Expert"
      icon={Sparkles}
      color="purple"
      selected={selected}
      className="w-[380px]"
      headerActions={
        <div className="flex items-center gap-1.5">
          {/* å¤šè½®å¯¹è¯çŠ¶æ€æŒ‡ç¤º */}
          {conversationId && (
            <span
              className="text-[10px] flex items-center gap-1 px-1.5 py-0.5 rounded-full bg-blue-100 dark:bg-blue-900/30 text-blue-600 dark:text-blue-400 font-medium cursor-pointer hover:bg-blue-200 dark:hover:bg-blue-900/50 transition-colors"
              title={`å¯¹è¯ä¸­ Â· ç¬¬ ${Math.ceil(conversationHistory.length / 2)} è½® Â· ${(conversationTokens / 1000).toFixed(1)}K tokens${hasCompressedHistory ? ' Â· å·²å‹ç¼©' : ''}`}
            >
              <MessageSquare className="w-3 h-3" />
              ç¬¬{Math.ceil(conversationHistory.length / 2)}è½®
            </span>
          )}
          {connectedImages.length > 0 ? (
            <span className="text-[10px] flex items-center gap-1 px-1.5 py-0.5 rounded-full bg-purple-100 dark:bg-purple-900/30 text-purple-600 dark:text-purple-400 font-medium">
              <Link2 className="w-3 h-3" />
              {connectedImages.length} å¼ å‚è€ƒå›¾
            </span>
          ) : (
            <span className="text-[10px] flex items-center gap-1 px-1.5 py-0.5 rounded-full bg-neutral-100 dark:bg-neutral-800 text-neutral-500 dark:text-neutral-400 font-medium opacity-60">
              â† å¯è¿æ¥å‚è€ƒå›¾
            </span>
          )}
          {isProcessing && (
            <Loader2 className="w-3.5 h-3.5 text-purple-600 animate-spin" />
          )}
        </div>
      }
    >
      {/* Left handle */}
      <Handle
        type="target"
        position={Position.Left}
        isConnectable={isConnectable}
        className="w-4 h-4 !bg-gradient-to-r !from-purple-500 !to-pink-500 !border-2 !border-white dark:!border-neutral-900 !rounded-full transition-all duration-200 hover:!scale-125 hover:!shadow-lg hover:!shadow-purple-500/50"
        title="è¿æ¥å›¾ç‰‡ä½œä¸ºå‚è€ƒ"
      />

      {/* Right handle */}
      <Handle
        type="source"
        position={Position.Right}
        isConnectable={isConnectable}
        className="w-4 h-4 !bg-gradient-to-r !from-purple-500 !to-violet-500 !border-2 !border-white dark:!border-neutral-900 !rounded-full"
      />

      {/* Reference images section */}
      {connectedImages.length > 0 && (
        <div className="bg-purple-50 dark:bg-purple-900/20 border border-purple-200 dark:border-purple-800 rounded-xl p-3 space-y-2">
          <div className="flex items-center gap-2 text-xs font-medium text-purple-700 dark:text-purple-300">
            <ImageIcon className="w-3.5 h-3.5" />
            å‚è€ƒå›¾ç”¨é€”
          </div>
          <div className="flex flex-col gap-2">
            <label className="flex items-center gap-2 cursor-pointer group">
              <input
                type="checkbox"
                checked={useForAnalysis}
                onChange={(e) => setUseForAnalysis(e.target.checked)}
                disabled={isProcessing}
                className="w-4 h-4 rounded border-purple-300 text-purple-600 focus:ring-purple-500 disabled:opacity-50"
              />
              <Eye className="w-3.5 h-3.5 text-purple-500" />
              <span className="text-[11px] text-neutral-700 dark:text-neutral-300">
                è®© AI åˆ†æå›¾ç‰‡ç”Ÿæˆæç¤ºè¯
              </span>
            </label>
            <label className="flex items-center gap-2 cursor-pointer group">
              <input
                type="checkbox"
                checked={useForImageGen}
                onChange={(e) => setUseForImageGen(e.target.checked)}
                disabled={isProcessing}
                className="w-4 h-4 rounded border-purple-300 text-purple-600 focus:ring-purple-500 disabled:opacity-50"
              />
              <Palette className="w-3.5 h-3.5 text-purple-500" />
              <span className="text-[11px] text-neutral-700 dark:text-neutral-300">
                ä½œä¸ºç”Ÿå›¾æ¨¡å‹å‚è€ƒå›¾
              </span>
            </label>
          </div>
          {/* Preview */}
          <div className="flex gap-1 mt-2 overflow-x-auto pb-1">
            {connectedImages.slice(0, 4).map((url, idx) => (
              <img
                key={idx}
                src={url}
                alt={`å‚è€ƒå›¾ ${idx + 1}`}
                className="w-10 h-10 rounded-lg object-cover border border-purple-200 dark:border-purple-700 flex-shrink-0"
              />
            ))}
            {connectedImages.length > 4 && (
              <div className="w-10 h-10 rounded-lg bg-purple-100 dark:bg-purple-800 flex items-center justify-center text-[10px] font-bold text-purple-600 dark:text-purple-300 flex-shrink-0">
                +{connectedImages.length - 4}
              </div>
            )}
          </div>
        </div>
      )}

      {/* Input area */}
      <div className="space-y-1">
        <NodeLabel>éœ€æ±‚æè¿°</NodeLabel>
        <NodeTextarea
          rows={3}
          value={userRequest}
          onChange={(e) => setUserRequest(e.target.value)}
          placeholder="æè¿°ä½ æƒ³è¦ç”Ÿæˆçš„å›¾ç‰‡ç±»å‹ï¼Œä¾‹å¦‚ï¼š&#10;â€¢ å…¬å¸ä»‹ç»PPTï¼Œ5é¡µï¼Œç§‘æŠ€é£æ ¼&#10;â€¢ 4æ­¥éª¤ä½¿ç”¨æ•™ç¨‹å›¾&#10;â€¢ çš®å…‹æ–¯é£æ ¼æ•…äº‹åœºæ™¯ï¼ˆ3ä¸ªåœºæ™¯ï¼‰..."
          disabled={isProcessing}
          className="focus:ring-purple-500/20 focus:border-purple-500"
        />
      </div>

      {/* Model & options - Tab style */}
      <div className="space-y-3">
        {/* Model selection */}
        <div className="space-y-1.5">
          <NodeLabel>æ¨¡å‹</NodeLabel>
          {isLoadingModels ? (
            <div className="flex items-center gap-2 text-xs text-neutral-500">
              <Loader2 className="w-3.5 h-3.5 animate-spin" />
              åŠ è½½æ¨¡å‹åˆ—è¡¨...
            </div>
          ) : modelOptions.length > 0 ? (
            <NodeTabSelect
              value={selectedModel}
              onChange={setSelectedModel}
              options={modelOptions}
              disabled={isProcessing}
              color="purple"
            />
          ) : (
            <div className="text-xs text-red-500">æ— å¯ç”¨æ¨¡å‹</div>
          )}
        </div>

        {/* å‚è€ƒå›¾è­¦å‘Š - å½“é€‰ä¸­çš„æ¨¡å‹ä¸æ”¯æŒå‚è€ƒå›¾ä½†è¿æ¥äº†å‚è€ƒå›¾æ—¶æ˜¾ç¤º */}
        {connectedImages.length > 0 && useForImageGen && !currentModelSupportsRef && (
          <div className="bg-amber-50 dark:bg-amber-900/20 border border-amber-200 dark:border-amber-800 rounded-lg p-2 flex gap-2 items-start">
            <AlertCircle className="w-4 h-4 text-amber-500 shrink-0 mt-0.5" />
            <p className="text-[11px] text-amber-600 dark:text-amber-400 leading-tight">
              å½“å‰æ¨¡å‹ä¸æ”¯æŒå‚è€ƒå›¾åŠŸèƒ½ï¼Œå‚è€ƒå›¾å°†ä»…ç”¨äº AI åˆ†æ
            </p>
          </div>
        )}

        {/* Resolution - æ ¹æ®æ¨¡å‹èƒ½åŠ›æ˜¾ç¤º */}
        {resolutionOptions.length > 0 && (
          <div className="space-y-1.5">
            <NodeLabel>åˆ†è¾¨ç‡</NodeLabel>
            <NodeTabSelect
              value={imageSize}
              onChange={setImageSize}
              options={resolutionOptions}
              disabled={isProcessing}
              color="purple"
              size="sm"
            />
          </div>
        )}

        {/* Aspect ratio - only when no reference images */}
        {!(connectedImages.length > 0 && useForImageGen) && aspectRatioOptions.length > 0 && (
          <div className="space-y-1.5">
            <NodeLabel>ç”»é¢æ¯”ä¾‹</NodeLabel>
            <NodeTabSelect
              value={aspectRatio}
              onChange={setAspectRatio}
              options={aspectRatioOptions}
              disabled={isProcessing}
              color="purple"
              size="sm"
            />
          </div>
        )}
      </div>

      {/* Options toggles */}
      <div className="space-y-2">
        <label className="flex items-center gap-2 cursor-pointer">
          <input
            type="checkbox"
            checked={autoGenerate}
            onChange={(e) => setAutoGenerate(e.target.checked)}
            disabled={isProcessing}
            className="w-4 h-4 rounded border-purple-300 text-purple-600 focus:ring-purple-500"
          />
          <span className="text-[11px] text-neutral-700 dark:text-neutral-300">
            ç”Ÿæˆæç¤ºè¯åè‡ªåŠ¨ç”Ÿæˆå›¾ç‰‡
          </span>
        </label>
        <div className="flex flex-col gap-1.5">
          <label className="flex items-center gap-2 cursor-pointer group">
            <input
              type="checkbox"
              checked={enableDeepResearch}
              onChange={(e) => setEnableDeepResearch(e.target.checked)}
              disabled={isProcessing}
              className="w-4 h-4 rounded border-purple-300 text-purple-600 focus:ring-purple-500"
            />
            <span className="text-[11px] text-neutral-700 dark:text-neutral-300 flex items-center gap-1">
              <Search className="w-3 h-3 text-purple-500" />
              å¯ç”¨æ·±åº¦ç ”ç©¶
            </span>
          </label>
          {enableDeepResearch && (
            <div className="ml-6 flex items-center gap-1.5">
              <span className="text-[10px] text-neutral-500 dark:text-neutral-400">å¼ºåº¦:</span>
              {[
                { value: 'low', label: 'å¿«é€Ÿ', time: '1-3åˆ†é’Ÿ', color: 'green' },
                { value: 'medium', label: 'æ ‡å‡†', time: '3-7åˆ†é’Ÿ', color: 'amber' },
                { value: 'high', label: 'æ·±åº¦', time: '7-15åˆ†é’Ÿ', color: 'red' },
              ].map((option) => (
                <button
                  key={option.value}
                  onClick={() => setReasoningEffort(option.value as 'low' | 'medium' | 'high')}
                  disabled={isProcessing}
                  className={`px-2 py-0.5 rounded text-[10px] transition-all ${
                    reasoningEffort === option.value
                      ? option.color === 'green'
                        ? 'bg-green-500 text-white'
                        : option.color === 'amber'
                        ? 'bg-amber-500 text-white'
                        : 'bg-red-500 text-white'
                      : 'bg-neutral-100 dark:bg-neutral-700 text-neutral-600 dark:text-neutral-300 hover:bg-neutral-200 dark:hover:bg-neutral-600'
                  }`}
                  title={option.time}
                >
                  {option.label}
                </button>
              ))}
              <span className="text-[9px] text-neutral-400 dark:text-neutral-500 ml-1">
                ~{reasoningEffort === 'low' ? '1-3' : reasoningEffort === 'medium' ? '3-7' : '7-15'}åˆ†é’Ÿ
              </span>
            </div>
          )}
        </div>
      </div>

      {/* Generate button */}
      <div className="flex gap-2">
        <NodeButton
          onClick={handleGenerate}
          disabled={!userRequest.trim() || isProcessing}
          className="flex-1 bg-gradient-to-r from-purple-500 to-violet-500 hover:from-purple-400 hover:to-violet-400 text-white"
        >
          {isProcessing ? (
            <>
              <Loader2 className="w-4 h-4 animate-spin" />
              æ€è€ƒä¸­ (è¿­ä»£ {currentIteration})
            </>
          ) : conversationId ? (
            <>
              <MessageSquare className="w-4 h-4" />
              ç»§ç»­å¯¹è¯
            </>
          ) : (
            <>
              <Sparkles className="w-4 h-4" />
              æ™ºèƒ½ç”Ÿæˆ
            </>
          )}
        </NodeButton>
        {conversationId && !isProcessing && (
          <NodeButton
            onClick={handleNewConversation}
            className="bg-neutral-500 hover:bg-neutral-400 text-white px-3"
            title="å¼€å§‹æ–°å¯¹è¯"
          >
            <RotateCcw className="w-4 h-4" />
          </NodeButton>
        )}
        {isProcessing && (
          <NodeButton onClick={handleStop} className="bg-red-500 hover:bg-red-400 text-white px-3">
            <StopCircle className="w-4 h-4" />
          </NodeButton>
        )}
      </div>

      {/* Conversation history - å¯¹è¯å†å²æ˜¾ç¤º */}
      {conversationId && (
        <div className="bg-blue-50 dark:bg-blue-900/20 border border-blue-200 dark:border-blue-800 rounded-xl p-3 space-y-2">
          <div className="flex items-center justify-between">
            <div className="flex items-center gap-2 text-xs font-medium text-blue-700 dark:text-blue-300">
              <MessageSquare className="w-3.5 h-3.5" />
              <span>å¤šè½®å¯¹è¯</span>
              <span className="text-[10px] px-1.5 py-0.5 rounded-full bg-blue-100 dark:bg-blue-900/40 text-blue-600 dark:text-blue-300 font-bold">
                ç¬¬ {Math.ceil(conversationHistory.length / 2)} è½®
              </span>
              <span className="text-[10px] px-1.5 py-0.5 rounded-full bg-neutral-100 dark:bg-neutral-800 text-neutral-600 dark:text-neutral-400">
                {(conversationTokens / 1000).toFixed(1)}K tokens
              </span>
              {hasCompressedHistory && (
                <span className="text-[10px] px-1.5 py-0.5 rounded-full bg-amber-100 dark:bg-amber-900/40 text-amber-600 dark:text-amber-300">
                  å·²å‹ç¼©
                </span>
              )}
            </div>
            {/* æ¸…ç©ºä¼šè¯æŒ‰é’® */}
            <button
              onClick={handleNewConversation}
              disabled={isProcessing}
              className="text-[10px] flex items-center gap-1 px-2 py-1 rounded-lg text-red-500 hover:text-red-600 hover:bg-red-50 dark:hover:bg-red-900/20 transition-colors disabled:opacity-50 disabled:cursor-not-allowed"
              title="æ¸…ç©ºä¼šè¯ï¼Œå¼€å§‹æ–°å¯¹è¯"
            >
              <Trash2 className="w-3 h-3" />
              æ¸…ç©º
            </button>
          </div>
          {conversationHistory.length > 0 && (
            <div className="max-h-24 overflow-y-auto space-y-1.5 pr-1">
              {conversationHistory.slice(-4).map((msg, idx) => (
                <div
                  key={idx}
                  className={`text-[11px] px-2 py-1.5 rounded-lg ${
                    msg.role === 'user'
                      ? 'bg-blue-100 dark:bg-blue-900/40 text-blue-800 dark:text-blue-200'
                      : 'bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300'
                  }`}
                >
                  <span className="font-medium">{msg.role === 'user' ? 'ä½ ï¼š' : 'AIï¼š'}</span>
                  {msg.content.length > 60 ? msg.content.substring(0, 60) + '...' : msg.content}
                </div>
              ))}
              {conversationHistory.length > 4 && (
                <div className="text-[10px] text-center text-blue-500 dark:text-blue-400">
                  ... è¿˜æœ‰ {conversationHistory.length - 4} æ¡æ›´æ—©çš„æ¶ˆæ¯
                </div>
              )}
            </div>
          )}
          {conversationHistory.length === 0 && (
            <div className="text-[11px] text-center text-blue-400 dark:text-blue-500 py-1">
              å¯¹è¯å·²å»ºç«‹ï¼Œè¾“å…¥é—®é¢˜ç»§ç»­äº¤æµ
            </div>
          )}
        </div>
      )}

      {/* Progress bar - ä½¿ç”¨æ–°çš„åŠ¨ç”»è¿›åº¦æ¡ */}
      {(isProcessing || progress > 0) && progress < 100 && (
        <AnimatedProgress
          progress={progress}
          status={isProcessing ? "æ¢ç´¢ä¸­..." : generatingCount > 0 ? `ç”Ÿæˆä¸­ (${generatingCount})` : "å‡†å¤‡ä¸­..."}
          variant="gradient"
          color="purple"
        />
      )}

      {/* å®æ—¶æ€è€ƒæµ - ä½¿ç”¨æ–°çš„æµå¼å±•ç¤ºç»„ä»¶ */}
      {isProcessing && streamingThought && (
        <StreamingThought
          content={streamingThought}
          iteration={currentIteration}
          isStreaming={true}
          toolName={thoughtSteps.length > 0 ? thoughtSteps[thoughtSteps.length - 1]?.action : undefined}
          className="animate-fade-in"
        />
      )}

      {/* Skill match badge - ä½¿ç”¨æ–°çš„æŠ€èƒ½å¾½ç«  */}
      {matchedSkill && (
        <SkillBadge
          name={matchedSkill.name}
          confidence={matchedSkill.confidence}
          className="animate-scale-in"
        />
      )}

      {/* ReAct process - ä½¿ç”¨æ–°çš„æ­¥éª¤æ—¶é—´çº¿ */}
      {thoughtSteps.length > 0 && (
        <div className="space-y-2">
          <button
            onClick={() => setShowDetails(!showDetails)}
            className="w-full flex items-center justify-between px-3 py-2.5 bg-gradient-to-r from-neutral-50 to-neutral-100 dark:from-neutral-800/50 dark:to-neutral-800 rounded-xl text-xs text-neutral-600 dark:text-neutral-300 hover:from-neutral-100 hover:to-neutral-150 dark:hover:from-neutral-800 dark:hover:to-neutral-700 transition-all border border-neutral-200/50 dark:border-neutral-700/50"
          >
            <span className="flex items-center gap-2">
              <Brain className="w-3.5 h-3.5 text-purple-500" />
              <span className="font-medium">æ€è€ƒè¿‡ç¨‹</span>
              <span className="text-[10px] px-1.5 py-0.5 rounded-full bg-purple-100 dark:bg-purple-900/40 text-purple-600 dark:text-purple-300">
                {thoughtSteps.length} æ­¥
              </span>
            </span>
            {showDetails ? <ChevronUp className="w-4 h-4" /> : <ChevronDown className="w-4 h-4" />}
          </button>

          {showDetails && (
            <div ref={stepsContainerRef} className="max-h-40 overflow-y-auto pr-1 animate-fade-in">
              <StepTimeline
                steps={thoughtSteps.map((step) => ({
                  id: step.iteration,
                  title: step.action ? TOOL_NAMES[step.action] || step.action : `è¿­ä»£ ${step.iteration}`,
                  description: step.thought?.substring(0, 50),
                  status: step.observation ? "completed" : isProcessing && step.iteration === currentIteration ? "active" : "pending",
                }))}
                variant="vertical"
                color="purple"
                compact
              />
            </div>
          )}
        </div>
      )}

      {/* Error */}
      {error && (
        <div className="px-3 py-2 bg-red-50 dark:bg-red-900/20 border border-red-200 dark:border-red-800 rounded-lg flex items-center gap-2">
          <XCircle className="w-4 h-4 text-red-500" />
          <span className="text-xs text-red-600 dark:text-red-400">{error}</span>
        </div>
      )}

      {/* Generated Prompts - ä½¿ç”¨æ–°çš„ PromptCard ç»„ä»¶ */}
      {prompts.length > 0 && (
        <div className="space-y-2">
          <div className="flex items-center justify-between">
            <div className="flex items-center gap-2">
              <NodeLabel className="mb-0">åœºæ™¯</NodeLabel>
              <span className="text-[10px] px-1.5 py-0.5 rounded-full bg-purple-100 dark:bg-purple-900/40 text-purple-600 dark:text-purple-300 font-bold">
                {prompts.length}
              </span>
            </div>
            <button
              onClick={handleCopyAll}
              className="text-[10px] text-purple-600 hover:text-purple-500 flex items-center gap-1 px-2 py-1 rounded-lg hover:bg-purple-50 dark:hover:bg-purple-900/20 transition-colors"
            >
              <Copy className="w-3 h-3" />
              å¤åˆ¶å…¨éƒ¨
            </button>
          </div>
          <div className="space-y-2 max-h-[220px] overflow-y-auto pr-1 scrollbar-thin scrollbar-thumb-purple-200 dark:scrollbar-thumb-purple-800">
            {prompts.map((prompt, index) => (
              <PromptCard
                key={prompt.id}
                scene={prompt.scene}
                prompt={prompt.prompt}
                chineseTexts={prompt.chineseTexts}
                status={prompt.status}
                error={prompt.error}
                onGenerate={!autoGenerate && prompt.status === "pending" ? () => handleGenerateSingle(prompt) : undefined}
                className={index === 0 ? "animate-fade-in" : ""}
              />
            ))}
          </div>
        </div>
      )}
    </BaseNode>
  );
};

export default memo(SuperAgentNode);
